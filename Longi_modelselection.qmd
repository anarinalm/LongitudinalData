# Model Selection {#sec-longi-modelselection}

```{r setup, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
knitr::opts_chunk$set(fig.height = 4)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.align="center")
`%notin%` <- Negate(`%in%`)
```

```{r, echo=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(haven))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(GGally))
suppressPackageStartupMessages(library(kableExtra))
```

```{r, echo=FALSE}
TLC <- read.csv("Data/TLC.csv")

### Convert Data from wide to Long
long_TLC <- tidyr::gather(TLC, level, measurements, lead0:lead6, factor_key=TRUE)
long_TLC <- long_TLC[order(long_TLC$id),]

#create new time variable for analyses
long_TLC$time <- c(0,1,4,6)[long_TLC$level]

#Note: other ways to code for time as continuous
# create new variable to make time continuous
long_TLC$week = 0 #baseline, week 0
long_TLC$week[long_TLC$level == "lead1"] = 1 #week 1
long_TLC$week[long_TLC$level == "lead4"] = 4 #week 4
long_TLC$week[long_TLC$level == "lead6"] = 6 #week 6
```


```{r}
library(tidyr) #Allows for us to manipulate the data structure
library(data.table) #Allows for us to manipulate the data structure
library(lme4) #Allows us to fit mixed effects models
library(lattice) #for plotting random effects
library(nlme)
```


## Comparing Mean Models

In this section, we will apply the backward selection method to 

Mod_base: $E(y_{ij} \mid X_{ij}) = \beta_0 + \beta_{trt}trt + \beta_{T}T + \beta_{T^2}T^2 + \beta_{trt:T}trt*T+\beta_{trt:T^2}trt*T^2$.

```{r}
# start off with baseline model including all terms
mod_base_unstruc <- gls(measurements ~ factor(group) + time + I(time^2) + factor(group):(time+ I(time^2)), 
                        data = long_TLC, corr = corSymm(form = ~ 1 | id),
                        weights = varIdent(form = ~1 | time), method = "REML")

summary(mod_base_unstruc)
```

```{r}
# If there were higher order terms that were significant we would 
# remove them, but in this case both interaction terms are significant 
# so we want to keep them in the model

# However, suppose the quadratic terms were not significant, 
# lets remove them here in this example
mod_second_unstruc <- gls(measurements ~ factor(group) + time + factor(group):(time), 
                          data = long_TLC, corr = corSymm(form = ~ 1 | id),
                          weights = varIdent(form = ~1 | time), method = "REML")

summary(mod_second_unstruc)
```

Note that all terms are now significant, including the interaction term. We used the backwards selection method to obtain the "best" model. Suppose we wanted to compare the mean models of mod_base_unstruc and mod_second_unstruc. We can compare model means using anova()

```{r}
anova(mod_base_unstruc,mod_second_unstruc)
```

Based on these results, which is the best model?

**Answer: The model called "mod_base_unstruc" is the best model which is consistent with our previous results**

## Comparing Covariance Models
In previous section, we fit three models on our data using various covariance structure below:

```{r}
# unstructured covariance  
mod_1_unstruc <- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level), 
                     data = long_TLC, corr = corSymm(form = ~ 1 | id),
                     weights = varIdent(form = ~1 | as.factor(level)), method = "REML")

# exchangeable (constant variances) 
mod_1_exch_const <- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level), 
                        data = long_TLC, corr = corCompSymm(form =  ~ factor(level)| id),
                        weights = varIdent(form = ~1), method = "REML")

# exchangeable (heterogeneous variances) 
mod_1_exch_heter <- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level), 
                        data = long_TLC, corr = corCompSymm(form = ~ factor(level)| id),
                        weights = varIdent(form = ~ 1 | factor(level)), method = "REML")
```

We can compare these models using `anova`.
```{r}
# compare three models together
anova(mod_1_unstruc, mod_1_exch_const, mod_1_exch_heter)
```

```{r}
# or compare two models at a time
anova(mod_1_unstruc, mod_1_exch_const)
anova(mod_1_exch_const, mod_1_exch_heter)
```

For model selection, we want to compare AIC and BIC. The model with the unstructured covariance (e.g., mod_1_unstruc) has the lowest AIC. The model with the exchangeable (heterogeneous variances) (e.g., mod_1_exch_heter) has the lowest BIC. These results suggest that the exchangeable (heterogeneous variances) fits the data best since it is more parsimonious and has low information. Based on the likelihood ratio test, the mod_1_exch_heter model is a significantly better fit than the other two models. 

