[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Longitudinal Tutorial",
    "section": "",
    "text": "Welcome\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2\n\n\nclustered data"
  },
  {
    "objectID": "Longi_EDA.html#long-and-wide-format",
    "href": "Longi_EDA.html#long-and-wide-format",
    "title": "1  Exploratory Data Analysis",
    "section": "1.1 Long and wide format",
    "text": "1.1 Long and wide format"
  },
  {
    "objectID": "Longi_GEE.html#package",
    "href": "Longi_GEE.html#package",
    "title": "2  Marginal Model (GEE)",
    "section": "2.1 Package",
    "text": "2.1 Package"
  },
  {
    "objectID": "Longi_modelselection.html#backward-forward-stepwise-model-selection",
    "href": "Longi_modelselection.html#backward-forward-stepwise-model-selection",
    "title": "6  Model Selection",
    "section": "6.1 Backward, Forward, Stepwise Model Selection",
    "text": "6.1 Backward, Forward, Stepwise Model Selection"
  },
  {
    "objectID": "Longi_interpretation.html#intercept",
    "href": "Longi_interpretation.html#intercept",
    "title": "9  Interpretation",
    "section": "9.1 Intercept",
    "text": "9.1 Intercept"
  },
  {
    "objectID": "Longi_noncontinuous.html#binary-outcome",
    "href": "Longi_noncontinuous.html#binary-outcome",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.7 Binary Outcome",
    "text": "10.7 Binary Outcome"
  },
  {
    "objectID": "Longi_noncontinuous.html#count-outcome",
    "href": "Longi_noncontinuous.html#count-outcome",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.8 Count Outcome",
    "text": "10.8 Count Outcome"
  },
  {
    "objectID": "Multi_EDA.html#visualization",
    "href": "Multi_EDA.html#visualization",
    "title": "12  Exploratory Data Analysis",
    "section": "12.1 Visualization",
    "text": "12.1 Visualization"
  },
  {
    "objectID": "Multi_noncontinuous.html#binary-outcome",
    "href": "Multi_noncontinuous.html#binary-outcome",
    "title": "19  Models for Non-Continuous Outcomes (Multilevel)",
    "section": "19.1 Binary Outcome",
    "text": "19.1 Binary Outcome"
  },
  {
    "objectID": "Multi_noncontinuous.html#count-outcome",
    "href": "Multi_noncontinuous.html#count-outcome",
    "title": "19  Models for Non-Continuous Outcomes (Multilevel)",
    "section": "19.2 Count Outcome",
    "text": "19.2 Count Outcome"
  },
  {
    "objectID": "Longi_intro.html#data-structure",
    "href": "Longi_intro.html#data-structure",
    "title": "Longitudinal Data Analysis",
    "section": "Data Structure",
    "text": "Data Structure\n\nsuppressPackageStartupMessages(library(tidyr))\nsuppressPackageStartupMessages(library(data.table))\nsuppressPackageStartupMessages(library(ggplot2))\nsuppressPackageStartupMessages(library(haven))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(GGally))\nsuppressPackageStartupMessages(library(kableExtra))\n\nThe most important part of any statistical analysis begins with loading the data into Rstudio. Data can come in many forms with two popular ones being csv (comma separated values) and dta. Below we show different methods for how to load the data into RStudio.\n\nLoading CSV files\n\nUsing base R\nThe following method is a pretty standard way of loading csv files into R. It requires no external packages (this is already a base R function) and works as follows. First, specify the location of your data, and put it into function as an input.\n\nTLC &lt;- read.csv(\"Data/TLC.csv\")\n\nWe can then get a look at the data by using the head function which provides us with a sneak peek of the first n rows.\n\nhead(TLC, n = 10)\n\n   id lead0 lead1 lead4 lead6     group\n1   1  30.8  26.9  25.8  23.8   Placebo\n2   2  26.5  14.8  19.5  21.0 Treatment\n3   3  25.8  23.0  19.1  23.2 Treatment\n4   4  24.7  24.5  22.0  22.5   Placebo\n5   5  20.4   2.8   3.2   9.4 Treatment\n6   6  20.4   5.4   4.5  11.9 Treatment\n7   7  28.6  20.8  19.2  18.4   Placebo\n8   8  33.7  31.6  28.5  25.1   Placebo\n9   9  19.7  14.9  15.3  14.7   Placebo\n10 10  31.1  31.2  29.2  30.1   Placebo\n\n\n\n\nUsing the readr package\nThe next method requires the use of the readr package. It works exactly the same as read.csv, save for the fact that it is faster than read.csv.\n\nlibrary(readr)\nTLC &lt;- read_csv(\"Data/TLC.csv\")\n\nWe can also print the first few rows to take a look of our data using function head, here we print the first 10 rows of the data.\n\nhead(TLC, n = 10)\n\n# A tibble: 10 × 6\n      id lead0 lead1 lead4 lead6 group    \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1     1  30.8 26.9   25.8 23.8  Placebo  \n 2     2  26.5 14.8   19.5 21    Treatment\n 3     3  25.8 23     19.1 23.2  Treatment\n 4     4  24.7 24.5   22   22.5  Placebo  \n 5     5  20.4  2.8    3.2  9.40 Treatment\n 6     6  20.4  5.40   4.5 11.9  Treatment\n 7     7  28.6 20.8   19.2 18.4  Placebo  \n 8     8  33.7 31.6   28.5 25.1  Placebo  \n 9     9  19.7 14.9   15.3 14.7  Placebo  \n10    10  31.1 31.2   29.2 30.1  Placebo  \n\n\n\n\nUsing the data.table package\nIf we have large datasets, we can use the fread function in the data.table package to read the data faster compared to the other methods above, and we print the first 5 rows of the data.\n\nlibrary(data.table)\nTLC &lt;- fread(\"Data/TLC.csv\")\nhead(TLC, n = 5)\n\n      id lead0 lead1 lead4 lead6     group\n   &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;    &lt;char&gt;\n1:     1  30.8  26.9  25.8  23.8   Placebo\n2:     2  26.5  14.8  19.5  21.0 Treatment\n3:     3  25.8  23.0  19.1  23.2 Treatment\n4:     4  24.7  24.5  22.0  22.5   Placebo\n5:     5  20.4   2.8   3.2   9.4 Treatment\n\n\n\n\n\nLoading dta files\nWe can also read files in other formats from other software (STATA, SPSS, SAS, etc). Here we will explore reading dta files which is used in STATA software. In order to load these into Rstudio we need to use a package known as haven. The haven package has a function known as read_dta() which serves a similar purpose as read.csv(), read_csv() and fread().\n\nTLCdta &lt;- read_dta(\"Data/TLC.dta\")\nhead(TLCdta, n = 15)\n\n# A tibble: 15 × 6\n      id lead0 lead1 lead4 lead6 group    \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1     1  30.8 26.9  25.8  23.8  Placebo  \n 2     2  26.5 14.8  19.5  21    Treatment\n 3     3  25.8 23    19.1  23.2  Treatment\n 4     4  24.7 24.5  22    22.5  Placebo  \n 5     5  20.4  2.80  3.20  9.40 Treatment\n 6     6  20.4  5.40  4.5  11.9  Treatment\n 7     7  28.6 20.8  19.2  18.4  Placebo  \n 8     8  33.7 31.6  28.5  25.1  Placebo  \n 9     9  19.7 14.9  15.3  14.7  Placebo  \n10    10  31.1 31.2  29.2  30.1  Placebo  \n11    11  19.8 17.5  20.5  27.5  Placebo  \n12    12  24.8 23.1  24.6  30.9  Treatment\n13    13  21.4 26.3  19.5  19    Placebo  \n14    14  27.9  6.30 18.5  16.3  Treatment\n15    15  21.1 20.3  18.4  20.8  Placebo"
  },
  {
    "objectID": "Longi_intro.html#converting-between-data-formats-wide-and-long-format",
    "href": "Longi_intro.html#converting-between-data-formats-wide-and-long-format",
    "title": "Longitudinal Data Analysis",
    "section": "Converting between data formats (wide and long format)",
    "text": "Converting between data formats (wide and long format)\nFor the most part there are two formats that your data can come in. The wide format and the long format. The long format is when patients within the data have more than one observation. In other words, each row is snapshot into a subject’s history at a specific time point. In the case of our data, each subject has four observations corresponding to their four lead measurements (initial measurement, 1 week measurement, 4 week measurement, and 6 week measurement). The code below details how to convert from wide format to long format.\nThe arguments to gather():\n\ndata: Data object (e.g. the data object here is TLC).\nkey: Name of new key column (made from names of data columns).\nvalue: Name of new value column.\n...: Names of source columns that contain values.\nfactor_key: Treat the new key column as a factor (instead of character vector).\n\nThen, we print the first 16 rows of the long format TLC data.\n\nlong_TLC &lt;- tidyr::gather(TLC, level, measurements, lead0:lead6, factor_key = TRUE)\nlong_TLC &lt;- long_TLC[order(long_TLC$id), ]\nhead(long_TLC, n = 16)\n\n    id     group level measurements\n1    1   Placebo lead0         30.8\n101  1   Placebo lead1         26.9\n201  1   Placebo lead4         25.8\n301  1   Placebo lead6         23.8\n2    2 Treatment lead0         26.5\n102  2 Treatment lead1         14.8\n202  2 Treatment lead4         19.5\n302  2 Treatment lead6         21.0\n3    3 Treatment lead0         25.8\n103  3 Treatment lead1         23.0\n203  3 Treatment lead4         19.1\n303  3 Treatment lead6         23.2\n4    4   Placebo lead0         24.7\n104  4   Placebo lead1         24.5\n204  4   Placebo lead4         22.0\n304  4   Placebo lead6         22.5\n\n\nThe wide format is when each row corresponds to a unique subject. The below shows one how to convert from long format to wide.\nThe arguments to spread():\n\ndata: Data object.\nkey: Name of column containing the new column names.\nvalue: Name of column containing values.\n\nThen, we print the first 10 rows of the converted wide format TLC data which should be same as our original data.\n\nwide_TLC &lt;- spread(long_TLC, level, measurements)\nhead(wide_TLC, n = 10)\n\n   id     group lead0 lead1 lead4 lead6\n1   1   Placebo  30.8  26.9  25.8  23.8\n2   2 Treatment  26.5  14.8  19.5  21.0\n3   3 Treatment  25.8  23.0  19.1  23.2\n4   4   Placebo  24.7  24.5  22.0  22.5\n5   5 Treatment  20.4   2.8   3.2   9.4\n6   6 Treatment  20.4   5.4   4.5  11.9\n7   7   Placebo  28.6  20.8  19.2  18.4\n8   8   Placebo  33.7  31.6  28.5  25.1\n9   9   Placebo  19.7  14.9  15.3  14.7\n10 10   Placebo  31.1  31.2  29.2  30.1"
  },
  {
    "objectID": "Longi_EDA.html#converting-between-data-formats-wide-and-long-format",
    "href": "Longi_EDA.html#converting-between-data-formats-wide-and-long-format",
    "title": "1  Exploratory Data Analysis",
    "section": "1.1 Converting between data formats (wide and long format)",
    "text": "1.1 Converting between data formats (wide and long format)\nFor the most part there are two formats that your data can come in. The wide format and the long format. The long format is when patients within the data have more than one observation. In other words, each row is snapshot into a subject’s history at a specific time point. In the case of our data, each subject has four observations corresponding to their four lead measurements (initial measurement, 1 week measurement, 4 week measurement, and 6 week measurement). The code below details how to convert from wide format to long format.\nThe arguments to gather():\n\ndata: Data object (e.g. the data object here is TLC).\nkey: Name of new key column (made from names of data columns).\nvalue: Name of new value column.\n...: Names of source columns that contain values.\nfactor_key: Treat the new key column as a factor (instead of character vector).\n\nThen, we print the first 16 rows of the long format TLC data.\n\nlong_TLC &lt;- tidyr::gather(TLC, level, measurements, lead0:lead6, factor_key = TRUE)\nlong_TLC &lt;- long_TLC[order(long_TLC$id), ]\nhead(long_TLC, n = 16)\n\n    id     group level measurements\n1    1   Placebo lead0         30.8\n101  1   Placebo lead1         26.9\n201  1   Placebo lead4         25.8\n301  1   Placebo lead6         23.8\n2    2 Treatment lead0         26.5\n102  2 Treatment lead1         14.8\n202  2 Treatment lead4         19.5\n302  2 Treatment lead6         21.0\n3    3 Treatment lead0         25.8\n103  3 Treatment lead1         23.0\n203  3 Treatment lead4         19.1\n303  3 Treatment lead6         23.2\n4    4   Placebo lead0         24.7\n104  4   Placebo lead1         24.5\n204  4   Placebo lead4         22.0\n304  4   Placebo lead6         22.5\n\n\nThe wide format is when each row corresponds to a unique subject. The below shows one how to convert from long format to wide.\nThe arguments to spread():\n\ndata: Data object.\nkey: Name of column containing the new column names.\nvalue: Name of column containing values.\n\nThen, we print the first 10 rows of the converted wide format TLC data which should be same as our original data.\n\nwide_TLC &lt;- spread(long_TLC, level, measurements)\nhead(wide_TLC, n = 10)\n\n   id     group lead0 lead1 lead4 lead6\n1   1   Placebo  30.8  26.9  25.8  23.8\n2   2 Treatment  26.5  14.8  19.5  21.0\n3   3 Treatment  25.8  23.0  19.1  23.2\n4   4   Placebo  24.7  24.5  22.0  22.5\n5   5 Treatment  20.4   2.8   3.2   9.4\n6   6 Treatment  20.4   5.4   4.5  11.9\n7   7   Placebo  28.6  20.8  19.2  18.4\n8   8   Placebo  33.7  31.6  28.5  25.1\n9   9   Placebo  19.7  14.9  15.3  14.7\n10 10   Placebo  31.1  31.2  29.2  30.1"
  },
  {
    "objectID": "Longi_EDA.html#data-structure",
    "href": "Longi_EDA.html#data-structure",
    "title": "1  Exploratory Data Analysis",
    "section": "1.2 Data Structure",
    "text": "1.2 Data Structure\nFor the most part there are two formats that your data can come in. The wide format and the long format. The long format is when patients within the data have more than one observation. In other words, each row is snapshot into a subject’s history at a specific time point. In the case of our data, each subject has four observations corresponding to their four lead measurements (initial measurement, 1 week measurement, 4 week measurement, and 6 week measurement). The code below details how to convert from wide format to long format.\nThe arguments to gather():\n\ndata: Data object (e.g. the data object here is TLC).\nkey: Name of new key column (made from names of data columns).\nvalue: Name of new value column.\n...: Names of source columns that contain values.\nfactor_key: Treat the new key column as a factor (instead of character vector).\n\nThen, we print the first 16 rows of the long format TLC data.\n\nlong_TLC &lt;- tidyr::gather(TLC, level, measurements, lead0:lead6, factor_key = TRUE)\nlong_TLC &lt;- long_TLC[order(long_TLC$id), ]\nhead(long_TLC, n = 16)\n\n    id     group level measurements\n1    1   Placebo lead0         30.8\n101  1   Placebo lead1         26.9\n201  1   Placebo lead4         25.8\n301  1   Placebo lead6         23.8\n2    2 Treatment lead0         26.5\n102  2 Treatment lead1         14.8\n202  2 Treatment lead4         19.5\n302  2 Treatment lead6         21.0\n3    3 Treatment lead0         25.8\n103  3 Treatment lead1         23.0\n203  3 Treatment lead4         19.1\n303  3 Treatment lead6         23.2\n4    4   Placebo lead0         24.7\n104  4   Placebo lead1         24.5\n204  4   Placebo lead4         22.0\n304  4   Placebo lead6         22.5\n\n\nThe wide format is when each row corresponds to a unique subject. The below shows one how to convert from long format to wide.\nThe arguments to spread():\n\ndata: Data object.\nkey: Name of column containing the new column names.\nvalue: Name of column containing values.\n\nThen, we print the first 10 rows of the converted wide format TLC data which should be same as our original data.\n\nwide_TLC &lt;- spread(long_TLC, level, measurements)\nhead(wide_TLC, n = 10)\n\n   id     group lead0 lead1 lead4 lead6\n1   1   Placebo  30.8  26.9  25.8  23.8\n2   2 Treatment  26.5  14.8  19.5  21.0\n3   3 Treatment  25.8  23.0  19.1  23.2\n4   4   Placebo  24.7  24.5  22.0  22.5\n5   5 Treatment  20.4   2.8   3.2   9.4\n6   6 Treatment  20.4   5.4   4.5  11.9\n7   7   Placebo  28.6  20.8  19.2  18.4\n8   8   Placebo  33.7  31.6  28.5  25.1\n9   9   Placebo  19.7  14.9  15.3  14.7\n10 10   Placebo  31.1  31.2  29.2  30.1"
  },
  {
    "objectID": "Longi_EDA.html#graphical-representation-of-longitudinal-data",
    "href": "Longi_EDA.html#graphical-representation-of-longitudinal-data",
    "title": "1  Exploratory Data Analysis",
    "section": "1.2 Graphical Representation of Longitudinal Data",
    "text": "1.2 Graphical Representation of Longitudinal Data\nIn this section we will create some visual representations of the data. While this is possible to do in base R, we will use ggplot. The plots look nicer and it is a reliable tool for making data visualizations. We will begin by plotting the blood lead level (BLL) trajectories for the first seven subjects.\n\n1.2.1 Individual Trajectory Plot\nWe need to utilize ggplot package to graph the individual trajectory plot. Before that, we firstly make some modification on our data. We create a new numeric column named time corresponding to the level column which represents the number of weeks for the measurement as our x-axis timing variable. Next, we convert the id column into factor so we can have each individual as a group.\n\n# create a new numeric timing variable\nlong_TLC$time &lt;- c(0, 1, 4, 6)[long_TLC$level]\n\n# convert the id column into factor for grouping\nlong_TLC$id &lt;- as.factor(long_TLC$id)\n\nNext, we are reading to graph the individual trajectory plot, and we only focus on the first 7 id’s individual.\n\n# create plot\nlead_trajectories &lt;- ggplot(data = long_TLC[(long_TLC[,\"id\"] %in% 1:7), ]) + #only focus on id's 1-7\n  geom_line(aes(x = time, y = measurements, color = id, group = id),size = 1.7) + \n  theme(axis.line = element_line(colour = \"black\", size = 2),\n        text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 16, face = \"bold\"),\n        axis.title = element_text(size = 16, face=\"bold\"),\n        axis.ticks.length = unit(.25, \"cm\"),\n        axis.ticks = element_line(colour = \"black\", size = 1.5),\n        legend.background = element_blank()) +\n  scale_color_manual(name = \"ID\", values = c(\"green\", \"red\", \"purple\", \"blue\",\n                                             \"yellow\", \"pink\", \"orange\"),\n                     labels = sapply(1:7, function(x) paste0(\"id\", \" = \", x))) +\n  ylab(~ paste(\"Blood Lead levels (\", mu, \"g/dL)\")) +\n  xlab(\"Time (weeks)\")\n\n# print the individual trajectory plot\nprint(lead_trajectories)\n\n\n\n\n\n\n\n\n\n\n1.2.2 Scatter Plot\nNext, we create a scatter plot to evaluate BLL over time. We stratify the data by group.\n\nlong_TLC$factor_time &lt;- as.factor(long_TLC$time)\n\n#create plot\nlead_point_plot &lt;- ggplot(long_TLC, \n                          aes(x = factor_time, y = measurements, color = group)) + \n  geom_point() + \n  facet_wrap(.~group) + # this allows us to make separate boxes for the groups\n  theme(axis.line = element_line(colour = \"black\", size = 2),\n        text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 16, face=\"bold\"),\n        axis.title = element_text(size = 16, face = \"bold\"),\n        axis.ticks.length=unit(.25, \"cm\"),\n        axis.ticks = element_line(colour = \"black\", size = 1.5)) + \n  ylab(~ paste(\"Blood Lead levels (\", mu, \"g/dL)\")) + \n  xlab(\"Time (weeks)\")\n\n# print the scatter plot\nprint(lead_point_plot)\n\n\n\n\n\n\n\n\n\n\n1.2.3 Mean Plot\nTo plot averages over time, we first summarize the data. Here we summarize count, mean, standard deviation (SD) and variance of blood lead levels over time (or for each occasion).\n\n#create table summarizing the blood lead levels\nlead_overall_summary &lt;- long_TLC %&gt;%\n  group_by(time) %&gt;% #CHECK\n  summarise(n = (length(measurements) - sum(is.na(measurements))),\n            mean = round(mean(measurements, na.rm = T), 3),\n            sd = round(sd(measurements, na.rm = T), 3),\n            var = round(var(measurements, na.rm = T), 3))\n\n#output table for overall averages\nlead_overall_summary %&gt;%\n  mutate_all(linebreak) %&gt;%\n  kbl(caption = \"Summary of average lead levels from TLC study\",\n      col.names=linebreak(c(\"Time\",\"N\", \"Mean\", \"SD\", \"Variance\")),\n      booktabs=T, escape=F, align = \"c\") %&gt;%\n  kable_styling(full_width = FALSE, latex_options = c('hold_position'))\n\n\nSummary of average lead levels from TLC study\n\n\nTime\nN\nMean\nSD\nVariance\n\n\n\n\n0\n100\n26.406\n4.999\n24.989\n\n\n1\n100\n19.091\n8.673\n75.225\n\n\n4\n100\n19.792\n8.086\n65.385\n\n\n6\n100\n22.204\n7.756\n60.159\n\n\n\n\n\n\n\nNext, we create a plot of means.\n\nlead_mean_plot &lt;- ggplot(data = lead_overall_summary, aes(x = time, y = mean)) +\n    geom_point(size = 2) + geom_line(size = 2) + ylab(~paste(\"Lead levels (\", mu,\n    \"g/dL)\")) + xlab(\"Time (weeks)\")\n\n# print the mean plot\nprint(lead_mean_plot)\n\n\n\n\n\n\n\n\n\n\n1.2.4 Box Plot\nAnother helpful method of visualizing the data is to use a boxplot. A boxplot is a standardized way of displaying the distribution of data based on five statistics: The minimum (bottom line), the 1st quartile (bottom of the box), the median (the line inside the box), the 3rd quartile (top of the box) and the maximum (top line). Sometimes you will encounter values that are above the maximum or below the minimum. These are known as outliers. This theoretically shouldn’t be true, but it occurs due to how the min and max are defined. The maximum is defined as the third quartile plus 1.5 times the InterQuartile Range (3rd quartile minus 1st quartile), and the minimum is defined as the 1st quartile minus 1.5 times the IQR.\n\nlead_box_plot &lt;- ggplot(long_TLC, aes(x = factor_time, y = measurements, fill = group)) +\n  geom_boxplot() +\n  facet_wrap(.~group) + #this is what allows us to make separate boxes for the groups\n  theme(axis.line = element_line(colour = \"black\", linewidth = 2),\n        text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 20, face = \"bold\"),\n        axis.title = element_text(size = 24, face =\"bold\"),\n        axis.ticks.length=unit(.25, \"cm\"),\n        axis.ticks = element_line(colour = \"black\", linewidth = 1.5)) +\n  ylab(~ paste(\" Lead levels ( \", mu, \"g/dL )\")) +\n  xlab(\"Time (weeks)\")\n\n# print the boxplot\nprint(lead_box_plot)\n\n\n\n\n\n\n\n\n\n\n1.2.5 Correlation Plot\nNext, we can create a correlation plot using GGally package.\n\nggpairs(TLC, columns = c(2:5))"
  },
  {
    "objectID": "Longi_EDA.html#descriptive-statistics-for-longitudinal-data",
    "href": "Longi_EDA.html#descriptive-statistics-for-longitudinal-data",
    "title": "1  Exploratory Data Analysis",
    "section": "1.3 Descriptive statistics for longitudinal data",
    "text": "1.3 Descriptive statistics for longitudinal data\nIn this section we will calculate some summary statistics for our continuous covariates. For simplicity I will be using the wide format of the data since every observation (i.e. row) will correspond to a unique id. There are many functions in R which will calculate any type of summary statistics you can think of. The most general is the summary() function in base R which calculates the minimum, 1st Quartile (25% Percentile), Median, Mean, 3rd Quartile (75%) and Maximum.\n\n1.3.1 Calculate summary statistics by group\n\n# Use by() function (in base R) to calculate summary statistics by Group\nby(TLC[, c(\"lead0\", \"lead1\", \"lead4\", \"lead6\")], TLC[, \"group\"], FUN = summary)\n\nTLC[, \"group\"]: Placebo\n     lead0           lead1           lead4           lead6      \n Min.   :19.70   Min.   :14.90   Min.   :15.30   Min.   :13.50  \n 1st Qu.:21.88   1st Qu.:20.93   1st Qu.:19.82   1st Qu.:19.95  \n Median :25.25   Median :24.10   Median :22.45   Median :22.35  \n Mean   :26.27   Mean   :24.66   Mean   :24.07   Mean   :23.65  \n 3rd Qu.:29.73   3rd Qu.:27.82   3rd Qu.:27.45   3rd Qu.:27.50  \n Max.   :38.10   Max.   :40.80   Max.   :38.60   Max.   :43.30  \n------------------------------------------------------------ \nTLC[, \"group\"]: Treatment\n     lead0           lead1            lead4            lead6      \n Min.   :19.70   Min.   : 2.800   Min.   : 3.000   Min.   : 4.10  \n 1st Qu.:22.12   1st Qu.: 7.225   1st Qu.: 9.125   1st Qu.:15.40  \n Median :26.20   Median :12.250   Median :15.350   Median :18.85  \n Mean   :26.54   Mean   :13.522   Mean   :15.514   Mean   :20.76  \n 3rd Qu.:29.55   3rd Qu.:17.500   3rd Qu.:19.725   3rd Qu.:23.75  \n Max.   :41.10   Max.   :39.000   Max.   :40.400   Max.   :63.90  \n\n\n\n\n1.3.2 Calculate summary statistics for all BLL data (not as groups)\n\nlead_all &lt;- c(TLC$lead0, TLC$lead1, TLC$lead4, TLC$lead6)\nsummary(lead_all)  #print summary statistics\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.80   17.50   21.90   21.87   26.73   63.90 \n\n\nIf you’re in need of even more summary statistics you can use the stat.desc package from the pastecs library.stat.desc provides you with the additional following descriptive statistics: the number of values (nbr.val), the number of null values (nbr.null), the number of missing values (nbr.na), the minimal value (min), the maximal value (max), the range (range, that is, max-min) and the sum of all non-missing values (sum), the median (median), the mean (mean), the standard error on the mean (SE.mean), the confidence interval of the mean (CI.mean) at the p level, the variance (var), the standard deviation (std.dev) and the variation coefficient (coef.var) defined as the standard deviation divided by the mean.\n\n### Calculate summary statistics by group\nlibrary(pastecs)\n# Use by() function (in base R) to calculate summary statistics by Group\nby(TLC[, c(\"lead0\", \"lead1\", \"lead4\", \"lead6\")], TLC[, \"group\"], FUN = stat.desc)\n\nTLC[, \"group\"]: Placebo\n                    lead0        lead1        lead4        lead6\nnbr.val        50.0000000   50.0000000   50.0000000   50.0000000\nnbr.null        0.0000000    0.0000000    0.0000000    0.0000000\nnbr.na          0.0000000    0.0000000    0.0000000    0.0000000\nmin            19.7000010   14.9000000   15.3000000   13.5000000\nmax            38.0999980   40.7999990   38.5999980   43.2999990\nrange          18.3999970   25.8999990   23.2999980   29.7999990\nsum          1313.5999970 1232.9999970 1203.5000030 1182.2999980\nmedian         25.2500000   24.0999995   22.4500010   22.3500005\nmean           26.2719999   24.6599999   24.0700001   23.6460000\nSE.mean         0.7105160    0.7723275    0.8136150    0.7975893\nCI.mean.0.95    1.4278353    1.5520502    1.6350205    1.6028157\nvar            25.2416481   29.8244892   33.0984669   31.8074323\nstd.dev         5.0241067    5.4611802    5.7531267    5.6398078\ncoef.var        0.1912343    0.2214591    0.2390165    0.2385100\n------------------------------------------------------------ \nTLC[, \"group\"]: Treatment\n                    lead0       lead1       lead4        lead6\nnbr.val        50.0000000  50.0000000  50.0000000   50.0000000\nnbr.null        0.0000000   0.0000000   0.0000000    0.0000000\nnbr.na          0.0000000   0.0000000   0.0000000    0.0000000\nmin            19.7000010   2.8000000   3.0000000    4.0999999\nmax            41.0999980  39.0000000  40.4000020   63.9000020\nrange          21.3999970  36.2000000  37.4000020   59.8000021\nsum          1326.9999960 676.0999983 775.6999992 1038.1000055\nmedian         26.2000000  12.2500000  15.3500000   18.8499995\nmean           26.5399999  13.5220000  15.5140000   20.7620001\nSE.mean         0.7100675   1.0850535   1.1104697    1.3076288\nCI.mean.0.95    1.4269341   2.1804967   2.2315724    2.6277784\nvar            25.2097935  58.8670567  61.6571480   85.4946530\nstd.dev         5.0209355   7.6724870   7.8522066    9.2463319\ncoef.var        0.1891837   0.5674077   0.5061368    0.4453488\n\n\nWhat do you observe in the variance-covariance matrices below? What happens when the units change? Write 1-3 sentences.\n\n### Covariance Matrix for lead levels in ug/dL\nround(cov(TLC[, c(\"lead0\", \"lead1\", \"lead4\", \"lead6\")]), 5)\n\n         lead0    lead1    lead4    lead6\nlead0 24.98905 18.16066 18.92146 21.78220\nlead1 18.16066 75.22487 59.24104 37.48690\nlead4 18.92146 59.24104 65.38539 36.54235\nlead6 21.78220 37.48690 36.54235 60.15898\n\n### Correlation Matrix for lead levels in mg/dL\nround(cov(TLC[, c(\"lead0\", \"lead1\", \"lead4\", \"lead6\")] * 10^-3), 6)\n\n        lead0   lead1   lead4   lead6\nlead0 2.5e-05 1.8e-05 1.9e-05 2.2e-05\nlead1 1.8e-05 7.5e-05 5.9e-05 3.7e-05\nlead4 1.9e-05 5.9e-05 6.5e-05 3.7e-05\nlead6 2.2e-05 3.7e-05 3.7e-05 6.0e-05\n\n\nWhat do you observe in the correlation matrices below? Write 1-3 sentences.\n\n### Correlation Matrix for lead levels in ug/dL\nround(cor(TLC[, c(\"lead0\", \"lead1\", \"lead4\", \"lead6\")]), 3)\n\n      lead0 lead1 lead4 lead6\nlead0 1.000 0.419 0.468 0.562\nlead1 0.419 1.000 0.845 0.557\nlead4 0.468 0.845 1.000 0.583\nlead6 0.562 0.557 0.583 1.000\n\n### Correlation Matrix for lead levels in mg/dL\nround(cor(TLC[, c(\"lead0\", \"lead1\", \"lead4\", \"lead6\")] * 10^-3), 3)\n\n      lead0 lead1 lead4 lead6\nlead0 1.000 0.419 0.468 0.562\nlead1 0.419 1.000 0.845 0.557\nlead4 0.468 0.845 1.000 0.583\nlead6 0.562 0.557 0.583 1.000"
  },
  {
    "objectID": "Longi_GEE.html#introduction",
    "href": "Longi_GEE.html#introduction",
    "title": "2  Marginal Model (GEE)",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nFor this lab we will return to the TLC dataset with N=100 participants in order to better understand marginal models for longitudinal data when the outcome is continuous."
  },
  {
    "objectID": "Longi_GEE.html#required-packages",
    "href": "Longi_GEE.html#required-packages",
    "title": "2  Marginal Model (GEE)",
    "section": "2.2 Required Packages",
    "text": "2.2 Required Packages\nWe will use the following packages:\n\nnlme: This package is for fitting and comparing Gaussian linear and nonlinear mixed-effects models. The variance-covariance structures for the residuals can be specified, and it is useful for data with repeated measures or longitudinal designs. We will use the gls() function to fit a linear model using generalized least squares.\nlme4: This package is for fitting mixed-effects models. We will use the lmer() function to fit a linear model.\n\nThese packages are for applying the generalized estimating equations (GEE) approach for fitting marginal generalized linear models to data with repeated measures or longitudinal designs:\n\ngee: This is the “Generalized Estimation Equation Solver” package.\ngpack: This is the “Generalized Estimating Equation Package” package.\ngeeM: This is the “Solve Generalized Estimating Equations” package.\n\n\nlibrary(tidyr)  #Allows for us to manipulate the data structure\nlibrary(data.table)  #Allows for us to manipulate the data structure\nlibrary(ggplot2)  #this makes better looking plots in R\n\n# new packages for models\nlibrary(nlme)  #used for the gls() function\nlibrary(gee)  # install.packages('gee'), used for the gee() function\nlibrary(geepack)  # install.packages('geepack'), used for the geeglm() function\nlibrary(geeM)  # install.packages('geeM'), used for the geeglm() function\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Longi_GEE.html#constructing-marginal-models",
    "href": "Longi_GEE.html#constructing-marginal-models",
    "title": "2  Marginal Model (GEE)",
    "section": "2.3 Constructing Marginal Models",
    "text": "2.3 Constructing Marginal Models\nConsider a continuous outcome \\(Y\\) which indicates a patient’s blood lead level (in micrograms per deciLiter \\(\\mu\\)g/dL). The correct way to write Y when doing a model like this would be as \\(Y_{ij}\\). \\(Y_{ij}\\) is the lead blood level of patient i at time point j. Likewise the covariates \\(X = (1,X^1, \\dots,X^p)\\) would be as \\(X_{ij} = (1,X^1_{ij},\\dots X^p_{ij})\\), the p covariates for individual i measured at time point j. 1 is simply the intercept. The superscript here just represents the \\(k-th\\) covariate in the analysis (i.e. in other words we have p covariates).\nIn these different modelling strategies we always specify a link between the mean of our distribution and the data, \\(E(y_{ij} \\mid X_{ij}) = \\mu_{ij} = g^{-1}(X^T_{ij}\\beta)\\). Here \\(g^{-1}\\) is what is commonly referred to as a link function. It is exactly what it sounds like. A function which links the mean of your distribution to your data. There are many common link functions that you’ve probably already dealt with in other regression courses. For example there is the logit link function \\(g(\\mu) =log(\\frac{\\mu}{1-\\mu}) = X^T\\beta\\) that one uses when doing logistic function.\nWhen one is doing linear regression a common link function is just the identity link \\(g(\\mu) =\\mu = X^T\\beta\\).\nHere we introduce a few functions and corresponding packages to fit these models:\n1. Using the gls() function to fit a linear model using generalized least squares\nThe syntax for the function gls() in nlme package is\ngls(model, data, correlation, weights, subset, method, na.action, control, verbose)\n\nDescription\n\nmodel: A two-sided linear formula object describing the model\ndata: Optional dataframe\ncorrelation: See description for details.\n\nThe corStruct object describes the within-group correlation structure.\nNote we use corCompSymm which has the following syntax: corCompSymm(value, form, fixed) compound symmetry structure corresponding to a constant correlation.\n\nweights: See description for details.\n\nDescribes the variance function.\nNote we use varClasses which defines standard classes of variance function structures and use varIdent which describes constant variance(s), that is generally used to allow different variances.\n\n\n\nWe consider the first model discussed in lecture. This model includes time as a categorical covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\nModel 1: \\[E(y_{ij} \\mid X_{ij}) = \\beta_0 +  \\beta_{trt}trt +  \\beta_{T_1}T_1 +  \\beta_{T_4}T_4 +  \\beta_{T_6}T_6 +  \\] \\[\\beta_{trt:T_1}trt*T_1+ \\beta_{trt:T_4}trt*T_4 + \\beta_{trt:T_6}trt*T_6\\]\n\n# Model fit with compound symmetry heterogeneous variances\n\n# Model 1: Response Profiles (time T categorical)\nfit.compsym &lt;- gls(measurements ~ factor(group) * factor(level), data = long_TLC,\n    corr = corCompSymm(, form = ~factor(level) | id), weights = varIdent(form = ~1 |\n        factor(level)))\nsummary(fit.compsym)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) * factor(level) \n  Data: long_TLC \n      AIC      BIC   logLik\n  2459.96 2511.587 -1216.98\n\nCorrelation Structure: Compound symmetry\n Formula: ~factor(level) | id \n Parameter estimate(s):\n      Rho \n0.6102726 \nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | factor(level) \n Parameter estimates:\n   lead0    lead1    lead4    lead6 \n1.000000 1.279673 1.323194 1.519223 \n\nCoefficients:\n                                            Value Std.Error   t-value p-value\n(Intercept)                                26.272 0.7237961  36.29751  0.0000\nfactor(group)Treatment                      0.268 1.0236023   0.26182  0.7936\nfactor(level)lead1                         -1.612 0.7506795  -2.14739  0.0324\nfactor(level)lead4                         -2.202 0.7713861  -2.85460  0.0045\nfactor(level)lead6                         -2.626 0.8726947  -3.00907  0.0028\nfactor(group)Treatment:factor(level)lead1 -11.406 1.0616211 -10.74395  0.0000\nfactor(group)Treatment:factor(level)lead4  -8.824 1.0909047  -8.08870  0.0000\nfactor(group)Treatment:factor(level)lead6  -3.152 1.2341767  -2.55393  0.0110\n\n Correlation: \n                                          (Intr) fct()T fct()1 fct()4 fct()6\nfactor(group)Treatment                    -0.707                            \nfactor(level)lead1                        -0.211  0.149                     \nfactor(level)lead4                        -0.181  0.128  0.402              \nfactor(level)lead6                        -0.060  0.043  0.383  0.383       \nfactor(group)Treatment:factor(level)lead1  0.149 -0.211 -0.707 -0.285 -0.270\nfactor(group)Treatment:factor(level)lead4  0.128 -0.181 -0.285 -0.707 -0.271\nfactor(group)Treatment:factor(level)lead6  0.043 -0.060 -0.270 -0.271 -0.707\n                                          f()T:()1 f()T:()4\nfactor(group)Treatment                                     \nfactor(level)lead1                                         \nfactor(level)lead4                                         \nfactor(level)lead6                                         \nfactor(group)Treatment:factor(level)lead1                  \nfactor(group)Treatment:factor(level)lead4  0.402           \nfactor(group)Treatment:factor(level)lead6  0.383    0.383  \n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.1429121 -0.6927784 -0.1528884  0.5263114  5.5480102 \n\nResidual standard error: 5.118012 \nDegrees of freedom: 400 total; 392 residual\n\n\n\nanova(fit.compsym)\n\nDenom. DF: 392 \n                            numDF   F-value p-value\n(Intercept)                     1 2438.1298  &lt;.0001\nfactor(group)                   1    7.1161   0.008\nfactor(level)                   3   80.5492  &lt;.0001\nfactor(group):factor(level)     3   46.9289  &lt;.0001\n\n\n2. Next, we discuss Marginal Models (GEE) and three R Packages \n**1. Using the `gee` package**\nThe syntax for the function gee() in gee package is\ngee(formula, id, data, family = gaussian, constr = ‘independence’,Mv)\n\nUsing the GEE Package\n\nformula: Symbolic description of the model to be fitted\nfamily: Description of the error distribution and link function\ndata: Optional dataframe\nid: Vector that identifies the clusters\nconstr: Working correlation structure: “independence”, “exchangeable”, “AR-M”, “unstructured”\nMv: order of AR correlation (AR1: Mv = 1)\n\n\nConsider the same model 1 defined earlier:\n\n# Model 1: Response Profiles (time T categorical)\nmod_tlc_gee &lt;- gee(measurements ~ level + group + level * group, id = id, data = long_TLC,\n    family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n              (Intercept)                levellead1                levellead4 \n                   26.272                    -1.612                    -2.202 \n               levellead6            groupTreatment levellead1:groupTreatment \n                   -2.626                     0.268                   -11.406 \nlevellead4:groupTreatment levellead6:groupTreatment \n                   -8.824                    -3.152 \n\nsummary(mod_tlc_gee)\n\n\n GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA\n gee S-function, version 4.13 modified 98/01/27 (1998) \n\nModel:\n Link:                      Identity \n Variance to Mean Relation: Gaussian \n Correlation Structure:     Unstructured \n\nCall:\ngee(formula = measurements ~ level + group + level * group, id = id, \n    data = long_TLC, family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\nSummary of Residuals:\n        Min          1Q      Median          3Q         Max \n-16.6620002  -4.6205000  -0.9930005   3.6724993  43.1380019 \n\n\nCoefficients:\n                          Estimate Naive S.E.    Naive z Robust S.E.\n(Intercept)                 26.272  0.9370175 28.0378980   0.7033749\nlevellead1                  -1.612  0.9958441 -1.6187272   0.4330324\nlevellead4                  -2.202  0.9838821 -2.2380730   0.4386752\nlevellead6                  -2.626  0.9316319 -2.8187098   0.5278091\ngroupTreatment               0.268  1.3251428  0.2022423   0.9944085\nlevellead1:groupTreatment  -11.406  1.4083363 -8.0989180   1.1086833\nlevellead4:groupTreatment   -8.824  1.3914194 -6.3417258   1.1408849\nlevellead6:groupTreatment   -3.152  1.3175265 -2.3923617   1.2439296\n                             Robust z\n(Intercept)                37.3513450\nlevellead1                 -3.7225849\nlevellead4                 -5.0196593\nlevellead6                 -4.9752836\ngroupTreatment              0.2695069\nlevellead1:groupTreatment -10.2878795\nlevellead4:groupTreatment  -7.7343471\nlevellead6:groupTreatment  -2.5339053\n\nEstimated Scale Parameter:  43.90009\nNumber of Iterations:  1\n\nWorking Correlation\n          [,1]      [,2]      [,3]      [,4]\n[1,] 1.0000000 0.4352485 0.4487346 0.5057310\n[2,] 0.4352485 1.0000000 0.8094551 0.6759677\n[3,] 0.4487346 0.8094551 1.0000000 0.6975035\n[4,] 0.5057310 0.6759677 0.6975035 1.0000000\n\n\n**2. Using the `geepack` package**\nThe syntax for the function geeglm() in geepack package is\ngeeglm(formula, family = gaussian, data, id, zcor = NULL, constr, std.err = ‘san.se’)\n\nUsing the geepack package\n\nformula: Symbolic description of the model to be fitted\nfamily: Description of the error distribution and link function\ndata: Optional dataframe\nid: Vector that identifies the clusters\ncontr: A character string specifying the correlation structure. The following are permitted: “independence”, “exchangeable”, “ar1”, “unstructured” and “userdefined”\nzcor: Enter a user defined correlation structure\n\n\nConsider the same model 1 defined earlier\n\n# Model 1: Response Profiles (time T categorical)\nmod_tlc_geep &lt;- geeglm(measurements ~ level + group + level * group, id = id, data = long_TLC,\n    family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\nsummary(mod_tlc_geep)\n\n\nCall:\ngeeglm(formula = measurements ~ level + group + level * group, \n    family = gaussian(link = \"identity\"), data = long_TLC, id = id, \n    corstr = \"unstructured\")\n\n Coefficients:\n                          Estimate  Std.err     Wald Pr(&gt;|W|)    \n(Intercept)                26.2720   0.7034 1395.123  &lt; 2e-16 ***\nlevellead1                 -1.6120   0.4330   13.858 0.000197 ***\nlevellead4                 -2.2020   0.4387   25.197 5.18e-07 ***\nlevellead6                 -2.6260   0.5278   24.753 6.52e-07 ***\ngroupTreatment              0.2680   0.9944    0.073 0.787540    \nlevellead1:groupTreatment -11.4060   1.1087  105.840  &lt; 2e-16 ***\nlevellead4:groupTreatment  -8.8240   1.1409   59.820 1.04e-14 ***\nlevellead6:groupTreatment  -3.1520   1.2439    6.421 0.011280 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)    43.02   6.583\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2   0.4352 0.07616\nalpha.1:3   0.4487 0.08482\nalpha.1:4   0.5057 0.05768\nalpha.2:3   0.8095 0.11232\nalpha.2:4   0.6760 0.10359\nalpha.3:4   0.6975 0.13711\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nWe can use the QIC() function from the geepack package.\n\nQIC(mod_tlc_geep)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n    17225     17225     -8604         8         8     17230 \n\n\n**3. Using the geeM package**\nThe syntax for the function geem() in geeM package is\ngeem(formula, id, waves = NULL, data, family = gaussian, constr = “independence”, Mv = 1)\n\nUsing the geeM package\n\nformula: Symbolic description of the model to be fitted\nid: Vector that identifies the clusters\ndata: Optional dataframe\nfamily: Description of the error distribution and link function\nconstr: A character string specifying the correlation structure. Allowed structures are: “independence”, “exchangeable” (equal correlation), “ar1” (exponential decay), “m-dependent” (m-diagonal), “unstructured”, “fixed”, and “userdefined”.\nMv: for “m-dependent”, the value for m.\n\n\nConsider the same model 1 defined earlier\n\n# Model 1: Response Profiles (time T categorical)\nmod_tlc_geeM &lt;- geem(measurements ~ level + group + level * group, id = id, data = long_TLC,\n    family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\nsummary(mod_tlc_geeM)\n\n                          Estimates Model SE Robust SE     wald         p\n(Intercept)                  26.270    1.143    0.7034  37.3500 0.000e+00\nlevellead1                   -1.612    1.543    0.4330  -3.7230 1.972e-04\nlevellead4                   -2.202    1.487    0.4387  -5.0200 5.200e-07\nlevellead6                   -2.626    1.270    0.5278  -4.9750 6.500e-07\ngroupTreatment                0.268    1.617    0.9944   0.2695 7.875e-01\nlevellead1:groupTreatment   -11.410    2.182    1.1090 -10.2900 0.000e+00\nlevellead4:groupTreatment    -8.824    2.103    1.1410  -7.7340 0.000e+00\nlevellead6:groupTreatment    -3.152    1.795    1.2440  -2.5340 1.128e-02\n\n Working Correlation: \n       [,1]   [,2]   [,3]   [,4]\n[1,] 1.0000 0.0893 0.1546 0.3835\n[2,] 0.0893 1.0000 1.0716 0.6018\n[3,] 0.1546 1.0716 1.0000 0.5901\n[4,] 0.3835 0.6018 0.5901 1.0000\n Correlation Structure:  unstructured \n Est. Scale Parameter:  65.36 \n\n Number of GEE iterations: 1 \n Number of Clusters:  100    Maximum Cluster Size:  4 \n Number of observations with nonzero weight:  400"
  },
  {
    "objectID": "Longi_GEE.html#response-profile-analysis",
    "href": "Longi_GEE.html#response-profile-analysis",
    "title": "2  Marginal Model (GEE)",
    "section": "2.4 Response Profile Analysis",
    "text": "2.4 Response Profile Analysis\nModel 1: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T_1}T_1 + \\beta_{T_4}T_4 + \\beta_{T_6}T_6 + \\beta_{trt:T_1}trt*T_1+ \\beta_{trt:T_4}trt*T_4 + \\beta_{trt:T_6}trt*T_6\\)\nThis model includes time as a categorical covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\nUsing the GLS approach, we can fit a model to include time, treatment, and their interaction as categorical variables (use dummy variables). What is your overall conclusion?\n\n# Recall the example above from the nlme package\n\n# Model 1: Response Profiles (time T categorical)\nresprof_gls_mod_1 &lt;- gls(measurements ~ factor(group) * factor(level), data = long_TLC,\n    corr = corCompSymm(, form = ~factor(level) | id), weights = varIdent(form = ~1 |\n        factor(level)))\n\n# Print summary\nsummary(resprof_gls_mod_1)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) * factor(level) \n  Data: long_TLC \n   AIC  BIC logLik\n  2460 2512  -1217\n\nCorrelation Structure: Compound symmetry\n Formula: ~factor(level) | id \n Parameter estimate(s):\n   Rho \n0.6103 \nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | factor(level) \n Parameter estimates:\nlead0 lead1 lead4 lead6 \n1.000 1.280 1.323 1.519 \n\nCoefficients:\n                                            Value Std.Error t-value p-value\n(Intercept)                                26.272    0.7238   36.30  0.0000\nfactor(group)Treatment                      0.268    1.0236    0.26  0.7936\nfactor(level)lead1                         -1.612    0.7507   -2.15  0.0324\nfactor(level)lead4                         -2.202    0.7714   -2.85  0.0045\nfactor(level)lead6                         -2.626    0.8727   -3.01  0.0028\nfactor(group)Treatment:factor(level)lead1 -11.406    1.0616  -10.74  0.0000\nfactor(group)Treatment:factor(level)lead4  -8.824    1.0909   -8.09  0.0000\nfactor(group)Treatment:factor(level)lead6  -3.152    1.2342   -2.55  0.0110\n\n Correlation: \n                                          (Intr) fct()T fct()1 fct()4 fct()6\nfactor(group)Treatment                    -0.707                            \nfactor(level)lead1                        -0.211  0.149                     \nfactor(level)lead4                        -0.181  0.128  0.402              \nfactor(level)lead6                        -0.060  0.043  0.383  0.383       \nfactor(group)Treatment:factor(level)lead1  0.149 -0.211 -0.707 -0.285 -0.270\nfactor(group)Treatment:factor(level)lead4  0.128 -0.181 -0.285 -0.707 -0.271\nfactor(group)Treatment:factor(level)lead6  0.043 -0.060 -0.270 -0.271 -0.707\n                                          f()T:()1 f()T:()4\nfactor(group)Treatment                                     \nfactor(level)lead1                                         \nfactor(level)lead4                                         \nfactor(level)lead6                                         \nfactor(group)Treatment:factor(level)lead1                  \nfactor(group)Treatment:factor(level)lead4  0.402           \nfactor(group)Treatment:factor(level)lead6  0.383    0.383  \n\nStandardized residuals:\n    Min      Q1     Med      Q3     Max \n-2.1429 -0.6928 -0.1529  0.5263  5.5480 \n\nResidual standard error: 5.118 \nDegrees of freedom: 400 total; 392 residual\n\n\nUsing the GEE approach, we can fit a model to include time, treatment, and their interaction as categorical variables (use dummy variables). Assume unstructured covariance model. Compare model estimates, standard errors, and covariance matrices with those from the methods you used in the previous question.\n\nmodel_1 &lt;- geeglm(measurements ~ group + as.factor(time) + as.factor(time) * group,\n    id = id, data = long_TLC, family = gaussian(link = \"identity\"), corstr = \"unstructured\")\nsummary(model_1)\n\n\nCall:\ngeeglm(formula = measurements ~ group + as.factor(time) + as.factor(time) * \n    group, family = gaussian(link = \"identity\"), data = long_TLC, \n    id = id, corstr = \"unstructured\")\n\n Coefficients:\n                                Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)                       26.272   0.703 1395.12  &lt; 2e-16 ***\ngroupTreatment                     0.268   0.994    0.07   0.7875    \nas.factor(time)1                  -1.612   0.433   13.86   0.0002 ***\nas.factor(time)4                  -2.202   0.439   25.20  5.2e-07 ***\nas.factor(time)6                  -2.626   0.528   24.75  6.5e-07 ***\ngroupTreatment:as.factor(time)1  -11.406   1.109  105.84  &lt; 2e-16 ***\ngroupTreatment:as.factor(time)4   -8.824   1.141   59.82  1.0e-14 ***\ngroupTreatment:as.factor(time)6   -3.152   1.244    6.42   0.0113 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)       43    6.58\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.435  0.0762\nalpha.1:3    0.449  0.0848\nalpha.1:4    0.506  0.0577\nalpha.2:3    0.809  0.1123\nalpha.2:4    0.676  0.1036\nalpha.3:4    0.698  0.1371\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\n\n# Recall the example above from the geepack package\n\n# Model 1: Response Profiles (time T categorical)\nresprof_gee_mod_1 &lt;- geeglm(measurements ~ level + group + level * group, id = id,\n    data = long_TLC, family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n# Print summary\nsummary(resprof_gee_mod_1)\n\n\nCall:\ngeeglm(formula = measurements ~ level + group + level * group, \n    family = gaussian(link = \"identity\"), data = long_TLC, id = id, \n    corstr = \"unstructured\")\n\n Coefficients:\n                          Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)                 26.272   0.703 1395.12  &lt; 2e-16 ***\nlevellead1                  -1.612   0.433   13.86   0.0002 ***\nlevellead4                  -2.202   0.439   25.20  5.2e-07 ***\nlevellead6                  -2.626   0.528   24.75  6.5e-07 ***\ngroupTreatment               0.268   0.994    0.07   0.7875    \nlevellead1:groupTreatment  -11.406   1.109  105.84  &lt; 2e-16 ***\nlevellead4:groupTreatment   -8.824   1.141   59.82  1.0e-14 ***\nlevellead6:groupTreatment   -3.152   1.244    6.42   0.0113 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)       43    6.58\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.435  0.0762\nalpha.1:3    0.449  0.0848\nalpha.1:4    0.506  0.0577\nalpha.2:3    0.809  0.1123\nalpha.2:4    0.676  0.1036\nalpha.3:4    0.698  0.1371\nNumber of clusters:   100  Maximum cluster size: 4 \n\n# Print QIC\nQIC(resprof_gee_mod_1)\n\n      QIC      QICu Quasi Lik       CIC    params      QICC \n    17225     17225     -8604         8         8     17230"
  },
  {
    "objectID": "Longi_GEE.html#parametric-curves",
    "href": "Longi_GEE.html#parametric-curves",
    "title": "2  Marginal Model (GEE)",
    "section": "2.5 Parametric Curves",
    "text": "2.5 Parametric Curves\n\n# create new variable to make time continuous\nlong_TLC$week = 0  #baseline, week 0 \nlong_TLC$week[long_TLC$level == \"lead1\"] = 1  #week 1\nlong_TLC$week[long_TLC$level == \"lead4\"] = 4  #week 4\nlong_TLC$week[long_TLC$level == \"lead6\"] = 6  #week 6\n\n\nparcurv_mod_2 &lt;- gls(measurements ~ factor(group) + week, data = long_TLC, corr = corCompSymm(,\n    form = ~week | id), weights = varIdent(form = ~1 | week), method = \"REML\")\n\n# Print summary\nsummary(parcurv_mod_2)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + week \n  Data: long_TLC \n   AIC  BIC logLik\n  2663 2695  -1323\n\nCorrelation Structure: Compound symmetry\n Formula: ~week | id \n Parameter estimate(s):\n  Rho \n0.659 \nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | week \n Parameter estimates:\n   0    1    4    6 \n1.00 2.22 1.83 1.54 \n\nCoefficients:\n                       Value Std.Error t-value p-value\n(Intercept)            26.53     0.742    35.8  0.0000\nfactor(group)Treatment  2.30     1.049     2.2  0.0291\nweek                   -0.58     0.098    -5.9  0.0000\n\n Correlation: \n                       (Intr) fct()T\nfactor(group)Treatment -0.707       \nweek                   -0.035  0.000\n\nStandardized residuals:\n    Min      Q1     Med      Q3     Max \n-2.5179 -1.0636 -0.3993  0.0715  4.5654 \n\nResidual standard error: 5.48 \nDegrees of freedom: 400 total; 397 residual"
  },
  {
    "objectID": "Longi_GEE.html#constructing-marginal-models-1",
    "href": "Longi_GEE.html#constructing-marginal-models-1",
    "title": "2  Marginal Model (GEE)",
    "section": "2.6 Constructing Marginal Models",
    "text": "2.6 Constructing Marginal Models\nModel 1: time is categorical, main effects, interaction terms\nModel 1: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T_1}T_1 + \\beta_{T_4}T_4 + \\beta_{T_6}T_6 + \\beta_{trt:T_1}trt*T_1+ \\beta_{trt:T_4}trt*T_4 + \\beta_{trt:T_6}trt*T_6\\)\nThis model includes time as a categorical covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\nmodel_1 &lt;- geeglm(measurements ~ group + as.factor(time) + as.factor(time) * group,\n    id = id, data = long_TLC, family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n# Print summary\nsummary(model_1)\n\n\nCall:\ngeeglm(formula = measurements ~ group + as.factor(time) + as.factor(time) * \n    group, family = gaussian(link = \"identity\"), data = long_TLC, \n    id = id, corstr = \"unstructured\")\n\n Coefficients:\n                                Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)                       26.272   0.703 1395.12  &lt; 2e-16 ***\ngroupTreatment                     0.268   0.994    0.07   0.7875    \nas.factor(time)1                  -1.612   0.433   13.86   0.0002 ***\nas.factor(time)4                  -2.202   0.439   25.20  5.2e-07 ***\nas.factor(time)6                  -2.626   0.528   24.75  6.5e-07 ***\ngroupTreatment:as.factor(time)1  -11.406   1.109  105.84  &lt; 2e-16 ***\ngroupTreatment:as.factor(time)4   -8.824   1.141   59.82  1.0e-14 ***\ngroupTreatment:as.factor(time)6   -3.152   1.244    6.42   0.0113 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)       43    6.58\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.435  0.0762\nalpha.1:3    0.449  0.0848\nalpha.1:4    0.506  0.0577\nalpha.2:3    0.809  0.1123\nalpha.2:4    0.676  0.1036\nalpha.3:4    0.698  0.1371\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 2: time is continuous, main effects\nModel 2: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T\\)\nThis model includes time as a continuous covariate and doesn’t specify any interaction between treatment and control groups.\n\nmodel_2 &lt;- geeglm(measurements ~ group + time, id = id, data = long_TLC, family = gaussian(link = \"identity\"),\n    corstr = \"unstructured\")\n\n# Print summary\nsummary(model_2)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time, family = gaussian(link = \"identity\"), \n    data = long_TLC, id = id, corstr = \"unstructured\")\n\n Coefficients:\n               Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)     25.5006  0.7040 1312.05  &lt; 2e-16 ***\ngroupTreatment  -5.3442  1.0307   26.89  2.2e-07 ***\ntime            -0.1510  0.0913    2.74    0.098 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)       56    7.57\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2  -0.0399  0.1068\nalpha.1:3   0.1088  0.1099\nalpha.1:4   0.4679  0.0820\nalpha.2:3   0.8603  0.0929\nalpha.2:4   0.4375  0.1145\nalpha.3:4   0.4881  0.1208\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 3: time is continuous, main effects, interaction term\nModel 3: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T + \\beta_{trt:T}trt*T\\)\nThis model includes time as a continuous covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\n# Define Model 3 and label it as: model_3\nmodel_3 &lt;- geeglm(measurements ~ group + time + time * group, id = id, data = long_TLC,\n    family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n# Print summary\nsummary(model_3)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time + time * group, \n    family = gaussian(link = \"identity\"), data = long_TLC, id = id, \n    corstr = \"unstructured\")\n\n Coefficients:\n                    Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)           25.589   0.707 1309.53  &lt; 2e-16 ***\ngroupTreatment        -5.694   1.054   29.19  6.5e-08 ***\ntime                  -0.265   0.102    6.74   0.0094 ** \ngroupTreatment:time    0.600   0.203    8.76   0.0031 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)     58.6    7.61\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2 -0.06469  0.1038\nalpha.1:3  0.00237  0.1233\nalpha.1:4  0.30449  0.1035\nalpha.2:3  0.92472  0.0824\nalpha.2:4  0.56396  0.1051\nalpha.3:4  0.56953  0.1160\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 4: time is continuous, time^2, main effects\nModel 4: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T + \\beta_{T^2}T^2\\)\nThis model treats time as a continuous covariate and also introduces a quadratic term. As a general note when adding quadratic, or higher power terms, into your regression you can either create a new covariate in your dataframe and put that into your formula, or you can take the existing one and specify the term as “I(x^2)”.\n\n# Define Model 4 and label it as: model_4\nmodel_4 &lt;- geeglm(measurements ~ group + time + I(time^2), id = id, data = long_TLC,\n    family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n# Print summary\nsummary(model_4)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time + I(time^2), family = gaussian(link = \"identity\"), \n    data = long_TLC, id = id, corstr = \"unstructured\")\n\n Coefficients:\n               Estimate Std.err   Wald Pr(&gt;|W|)    \n(Intercept)     26.1837  0.7144 1343.5  &lt; 2e-16 ***\ngroupTreatment  -5.1837  1.0267   25.5  4.4e-07 ***\ntime            -2.0829  0.4685   19.8  8.7e-06 ***\nI(time^2)        0.3299  0.0809   16.6  4.5e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)     52.3    6.93\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.055  0.1133\nalpha.1:3    0.241  0.1109\nalpha.1:4    0.435  0.0903\nalpha.2:3    0.801  0.1005\nalpha.2:4    0.531  0.1120\nalpha.3:4    0.548  0.1177\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 5: time is continuous, time^2, main effects, interaction\nModel 5: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T + \\beta_{T^2}T^2 + \\beta_{trt:T}trt*T+\\beta_{trt:T^2}trt*T^2\\)\nThis model includes time as a continuous covariate and also includes a quadratic term to capture any possible non-linearity in time and an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\n# Define Model 5 and label it as: model_5\n\nmodel_5 &lt;- geeglm(measurements ~ group + time + I(time^2) + group:(time + I(time^2)),\n    id = id, data = long_TLC, family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n# Print summary\nsummary(model_5)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time + I(time^2) + group:(time + \n    I(time^2)), family = gaussian(link = \"identity\"), data = long_TLC, \n    id = id, corstr = \"unstructured\")\n\n Coefficients:\n                         Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)               25.7785  0.6915 1389.59  &lt; 2e-16 ***\ngroupTreatment            -3.4262  1.0497   10.65   0.0011 ** \ntime                      -0.6750  0.2567    6.91   0.0085 ** \nI(time^2)                  0.0619  0.0417    2.20   0.1377    \ngroupTreatment:time       -4.8098  0.8088   35.36  2.7e-09 ***\ngroupTreatment:I(time^2)   0.8814  0.1393   40.00  2.5e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)     48.5     6.6\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.199  0.1099\nalpha.1:3    0.399  0.0988\nalpha.1:4    0.333  0.1149\nalpha.2:3    0.718  0.1067\nalpha.2:4    0.719  0.1011\nalpha.3:4    0.619  0.1175\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nNow that we have our five models how exactly can we go about choosing which one is the best?\nA common method of model selection is using the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). For reference \\(AIC = 2p - 2log(L)\\) where \\(L\\) is the likelihood and p is the number of covariates (excluding the intercept). Similarly $BIC = plog(n) - 2log(L) $ where n is the sample size of the data. As an aside when we say log() we are strictly talking about the natural logarithm.\nGiven a collection of models \\(\\{ \\mathcal{M}_m \\}^M_{m=1}\\) we would like to know which one to choose. AIC and BIC both reward goodness of fit (as assessed by the likelihood function), but this can lead to problems in overfitting (i.e. using too much information that makes a model too specific). Overfitting could arise because increasing the number of covariates could cause the likelihood \\(\\hat{L}\\) to increase. To counteract this problem both the AIC and BIC introduce a penalty term that is meant to punish models that are built with a high number of predictors (predictors is synonymous with covariates). AIC uses the \\(2p\\) penalty and BIC uses the \\(plog(n)\\) penalty. Unfortunately for us using the AIC and BIC requires for their to be an actual likelihood. GEE’s don’t have likelihood’s attached to them so it would be non-sensical for us to use either AIC or BIC to select a model.\nOne way to work around this issue is through the introduction of the Quasi-likelihood Information Criterion (QIC). Developed by Pan (2001), the QIC is a modification of the AIC for models fitted by GEE. Using the QIC() function from the geepack package we can calculate the QIC’s of each model and see which of the five has the minimum QIC.\n\nQIC_comparisons &lt;- data.frame(`Model Name` = c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\",\n    \"Model 5\"), QIC = c(QIC(model_1)[1], QIC(model_2)[1], QIC(model_3)[1], QIC(model_4)[1],\n    QIC(model_5)[1]))\nQIC_comparisons\n\n  Model.Name   QIC\n1    Model 1 17225\n2    Model 2 22419\n3    Model 3 23441\n4    Model 4 20927\n5    Model 5 19397\n\n\nFrom the above we can see that Model 1 has the smallest QIC out of the five models."
  },
  {
    "objectID": "Longi_GEEinterpretation.html#brief-review-of-what-we-learned",
    "href": "Longi_GEEinterpretation.html#brief-review-of-what-we-learned",
    "title": "3  Marginal Model Interpretation",
    "section": "3.1 Brief Review of What We Learned",
    "text": "3.1 Brief Review of What We Learned\n\n\nMarginal Models\n\nGLS\n\nDefine covariance model\nCompare models using AIC, BIC, likelihood ratio test\n\nGEE\n\nCompare models using QIC\nDefine covariance model and link function\n\n\n\n\nlibrary(nlme)  #used for the gls() function"
  },
  {
    "objectID": "Longi_GEEinterpretation.html#interpreting-coefficients-of-marginal-models-systematic-component",
    "href": "Longi_GEEinterpretation.html#interpreting-coefficients-of-marginal-models-systematic-component",
    "title": "3  Marginal Model Interpretation",
    "section": "3.2 Interpreting Coefficients of Marginal Models (Systematic Component)",
    "text": "3.2 Interpreting Coefficients of Marginal Models (Systematic Component)\nFirst, lets consider a few simple cases in understanding the Marginal Model:\n\\[\\mu_{ij} = E(\\textcolor{red}{y}_{ij} \\mid {X_{ij},t_{ij}})\\]\nwhere \\(X_{ij}\\) are the explanatory variables and \\(t_{ij}\\) is time.\n\nIf the mean is constant across time and other variables (\\(X_{ij}\\)), and the mean is the same for all individuals, then\n\n\\[\\mu_{ij} = \\mu\\]\n\nIf the mean changes across time linearly and is not impacted by other variables (\\(X_{i}\\)), and is the same for all individuals, then\n\n\\[\\mu_{ij} = \\beta_0 + \\beta_1 t_{ij}\\]\n\nIf the mean changes across time with time-varying variables (\\(X_{ij}\\)) and is the same for all individuals, then\n\n\\[\\mu_{ij} = \\beta_0 + \\beta_1 x_{ij}\\]\nNow, lets go back to interpreting coefficients of our models\n\n# unstructured covariance\nmarg_mod &lt;- gls(measurements ~ factor(group) + time, data = long_TLC, corr = corSymm(form = ~1 |\n    id), weights = varIdent(form = ~1 | as.factor(level)), method = \"REML\")\n\nsummary(marg_mod)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + time \n  Data: long_TLC \n       AIC      BIC    logLik\n  2583.433 2635.224 -1278.716\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1     2     3    \n2 0.124            \n3 0.247 0.856      \n4 0.518 0.455 0.522\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | as.factor(level) \n Parameter estimates:\n   lead0    lead1    lead4    lead6 \n1.000000 1.836722 1.583388 1.437453 \n\nCoefficients:\n                           Value Std.Error  t-value p-value\n(Intercept)            26.053146 0.6930432 37.59238  0.0000\nfactor(group)Treatment -2.012020 0.9786776 -2.05586  0.0404\ntime                   -0.399965 0.0862719 -4.63610  0.0000\n\n Correlation: \n                       (Intr) fct()T\nfactor(group)Treatment -0.706       \ntime                   -0.054  0.000\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.3061017 -0.7995745 -0.3107700  0.3410439  5.5215819 \n\nResidual standard error: 5.324253 \nDegrees of freedom: 400 total; 397 residual\n\n\n\\(\\beta_{trt}\\) and \\(\\beta_{T}\\) represents the estimated population mean change.\nThe general interpretation for these coeffiecients when \\(X_{ij}\\) is continuous, is that a unit difference in \\(X\\) leads to a \\(\\beta_1\\) difference in overall mean response while holding all other variables constant.\nLets interpret these coefficients in the context of the TLC data.\nInterpretation:\n\\(\\beta_{trt}\\): Among the treatment group, the average population change of blood lead levels (BLL) decreases by 2 in comparison to the control group.\n\\(\\beta_{T}\\): Among the control and treatment groups, blood lead levels (BLL) decreases by 0.40 (\\(\\beta_{T}\\)) for every one-unit increase in time (\\(T\\)).\n\\(\\beta_{0}\\): Among the control and treatment group, the average population change of blood lead levels (BLL) increases by 26 and is constant over time.\nHow would our interpretation change after adding an interaction term?\nConsider the following model:\n\n# unstructured covariance\nmarg_mod_inter &lt;- gls(measurements ~ factor(group) + time + factor(group):time, data = long_TLC,\n    corr = corSymm(form = ~1 | id), weights = varIdent(form = ~1 | as.factor(level)),\n    method = \"REML\")\n\nsummary(marg_mod_inter)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + time + factor(group):time \n  Data: long_TLC \n       AIC      BIC    logLik\n  2586.646 2642.386 -1279.323\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1     2     3    \n2 0.132            \n3 0.271 0.846      \n4 0.543 0.406 0.495\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | as.factor(level) \n Parameter estimates:\n   lead0    lead1    lead4    lead6 \n1.000000 1.833984 1.551842 1.439514 \n\nCoefficients:\n                                Value Std.Error  t-value p-value\n(Intercept)                 26.039582 0.6940593 37.51780  0.0000\nfactor(group)Treatment      -1.938410 0.9815481 -1.97485  0.0490\ntime                        -0.368743 0.1223416 -3.01404  0.0027\nfactor(group)Treatment:time -0.169559 0.1730172 -0.98001  0.3277\n\n Correlation: \n                            (Intr) fct()T time  \nfactor(group)Treatment      -0.707              \ntime                        -0.077  0.054       \nfactor(group)Treatment:time  0.054 -0.077 -0.707\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.2991338 -0.7973523 -0.2854753  0.3570825  5.6284768 \n\nResidual standard error: 5.310688 \nDegrees of freedom: 400 total; 396 residual\n\n\nInterpretation:\n\\(\\beta_{0}\\): Among the control and treatment groups, the average population change of blood lead levels (BLL) increases by 26 and is constant over time.\n\\(\\beta_{trt}\\): Among the treatment group, the average population change of blood lead levels (BLL) decreases by 1.93 in comparison to the control group.\n\\(\\beta_{T}\\): Among the control group, blood lead levels (BLL) decreases by 0.40 (\\(\\beta_{T}\\)) for every one-unit increase in time (\\(T\\)).\n\\(\\beta_{T} + \\beta_{trt:T}\\): Among the treatment groups, blood lead levels (BLL) decreases by 2.09 for every one-unit increase in time (\\(T\\)).\n\\(\\beta_{trt:T}\\): Comparing the treatment and control groups, the difference in the mean change of blood lead levels (BLL) is 0.20 less among the patients in the treatment group compared to the control group for every one-unit increase in time (\\(T\\)).\nHow would this change if time was categorical?\nConsider the Response Profiles Analysis case with no interaction terms first:\n\n# unstructured covariance\nmarg_mod_resp_prof &lt;- gls(measurements ~ factor(group) + factor(level), data = long_TLC,\n    corr = corSymm(form = ~1 | id), weights = varIdent(form = ~1 | as.factor(level)),\n    method = \"REML\")\n\nsummary(marg_mod_resp_prof)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + factor(level) \n  Data: long_TLC \n       AIC      BIC    logLik\n  2525.171 2584.854 -1247.585\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1     2     3    \n2 0.334            \n3 0.407 0.822      \n4 0.551 0.512 0.550\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | as.factor(level) \n Parameter estimates:\n   lead0    lead1    lead4    lead6 \n1.000000 1.567427 1.478107 1.484946 \n\nCoefficients:\n                           Value Std.Error  t-value p-value\n(Intercept)            27.412078 0.7104367 38.58483  0.0000\nfactor(group)Treatment -2.012157 0.9786873 -2.05598  0.0404\nfactor(level)lead1     -7.315000 0.7993319 -9.15139  0.0000\nfactor(level)lead4     -6.614000 0.7247826 -9.12549  0.0000\nfactor(level)lead6     -4.202000 0.6448472 -6.51627  0.0000\n\n Correlation: \n                       (Intr) fct()T fct()1 fct()4\nfactor(group)Treatment -0.689                     \nfactor(level)lead1     -0.222  0.000              \nfactor(level)lead4     -0.205  0.000  0.814       \nfactor(level)lead6     -0.105  0.000  0.437  0.446\n\nStandardized residuals:\n        Min          Q1         Med          Q3         Max \n-2.23559995 -0.64349381 -0.04593544  0.61603803  5.58341353 \n\nResidual standard error: 5.15037 \nDegrees of freedom: 400 total; 395 residual\n\n\nInterpretation:\n\\(\\beta_{0}\\): Among the control and treatment groups, the average population change of blood lead levels (BLL) increases by 27.41 and is constant over time.\n\\(\\beta_{trt}\\): Among the treatment group, the average population change of blood lead levels (BLL) decreases by 2.01 in comparison to the control group.\n\\(\\beta_{T_1}, \\beta_{T_4}, \\beta_{T_6}\\): represent the average change in blood lead levels (BLL) among the population (e.g. both control and treatment groups) relative to baseline which is the reference group for each time variable (dichotomous indicator variable).\nFor example, the average change in blood lead levels (BLL) among the population is 7.31 less compared to the baseline measure.\nHow would this change if an interaction term was included in the model?\nConsider the Response Profiles Analysis case with no interaction terms first:\n\n# unstructured covariance\nmarg_mod_resp_prof &lt;- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level),\n    data = long_TLC, corr = corSymm(form = ~1 | id), weights = varIdent(form = ~1 |\n        as.factor(level)), method = \"REML\")\n\nsummary(marg_mod_resp_prof)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + factor(level) + factor(group):factor(level) \n  Data: long_TLC \n       AIC      BIC    logLik\n  2452.076 2523.559 -1208.038\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1     2     3    \n2 0.571            \n3 0.570 0.775      \n4 0.577 0.582 0.581\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | as.factor(level) \n Parameter estimates:\n   lead0    lead1    lead4    lead6 \n1.000000 1.325881 1.370473 1.524828 \n\nCoefficients:\n                                            Value Std.Error   t-value p-value\n(Intercept)                                26.272 0.7102870  36.98787  0.0000\nfactor(group)Treatment                      0.268 1.0044975   0.26680  0.7898\nfactor(level)lead1                         -1.612 0.7919161  -2.03557  0.0425\nfactor(level)lead4                         -2.202 0.8149208  -2.70210  0.0072\nfactor(level)lead6                         -2.626 0.8885227  -2.95547  0.0033\nfactor(group)Treatment:factor(level)lead1 -11.406 1.1199385 -10.18449  0.0000\nfactor(group)Treatment:factor(level)lead4  -8.824 1.1524721  -7.65658  0.0000\nfactor(group)Treatment:factor(level)lead6  -3.152 1.2565608  -2.50843  0.0125\n\n Correlation: \n                                          (Intr) fct()T fct()1 fct()4 fct()6\nfactor(group)Treatment                    -0.707                            \nfactor(level)lead1                        -0.218  0.154                     \nfactor(level)lead4                        -0.191  0.135  0.680              \nfactor(level)lead6                        -0.096  0.068  0.386  0.385       \nfactor(group)Treatment:factor(level)lead1  0.154 -0.218 -0.707 -0.481 -0.273\nfactor(group)Treatment:factor(level)lead4  0.135 -0.191 -0.481 -0.707 -0.272\nfactor(group)Treatment:factor(level)lead6  0.068 -0.096 -0.273 -0.272 -0.707\n                                          f()T:()1 f()T:()4\nfactor(group)Treatment                                     \nfactor(level)lead1                                         \nfactor(level)lead4                                         \nfactor(level)lead6                                         \nfactor(group)Treatment:factor(level)lead1                  \nfactor(group)Treatment:factor(level)lead4  0.680           \nfactor(group)Treatment:factor(level)lead6  0.386    0.385  \n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.1756425 -0.6849970 -0.1515552  0.5294183  5.6327493 \n\nResidual standard error: 5.022487 \nDegrees of freedom: 400 total; 392 residual\n\n\nInterpretation of Interaction Term Parameters:\n\\(\\beta_{T_1}, \\beta_{T_4}, \\beta_{T_6}\\): represent the average change in blood lead levels (BLL) among the control group relative to baseline which is the reference group in this case for each time variable (dichotomous indicator variable).\n\\(\\beta_{T_1} + \\beta_{trt:T1}, \\beta_{T_4} + \\beta_{trt:T4}, \\beta_{T_6} + \\beta_{trt:T6}\\): represent the average change in blood lead levels (BLL) among the treatment group compared to control group relative to baseline which is the reference group in this case for each time variable (dichotomous indicator variable).\nFor example, the average change in blood lead levels (BLL) among the treatment group at week 1 compared to baseline is 13.02 less (\\(\\beta_{T_1} + \\beta_{trt:T1}\\)) in comparison to the control group at visit 1. Notice that there are two references here in our interpretation: the group (treatment vs control) and the time point (week 1 vs baseline).\n\\(\\beta_{trt:T1}, \\beta_{trt:T4}, \\beta_{trt:T6}\\): represent the average difference in mean blood lead levels (BLL) between treatment groups at the different time points in comparison to baseline which is the reference group.\nFor example, the average difference in mean blood lead levels (BLL) from baseline to week 1 was 11.40 (\\(\\beta_{trt:T1}\\)) between treatment groups."
  },
  {
    "objectID": "Longi_mixeffect.html#brief-review-of-what-we-learned-so-far",
    "href": "Longi_mixeffect.html#brief-review-of-what-we-learned-so-far",
    "title": "4  Mixed Effects Model",
    "section": "4.2 Brief Review of what we learned so far",
    "text": "4.2 Brief Review of what we learned so far\nModels for LDA with Continuous Outcomes\n\nMarginal Models\n\nGLS\n\nDefine covariance model\nCompare models using AIC, BIC, likelihood ratio test\n\nGEE\n\nCompare models using QIC\nDefine covariance model and link function\n\n\n\n\nSpecify random effects\nCompare models using AIC, BIC\nOther packages allow you to specify the covariance model"
  },
  {
    "objectID": "Longi_mixeffect.html#section-4-fitting-mixed-effect-models-to-the-tlc-data",
    "href": "Longi_mixeffect.html#section-4-fitting-mixed-effect-models-to-the-tlc-data",
    "title": "4  Mixed Effects Model",
    "section": "4.3 Section 4: Fitting Mixed Effect Models to the TLC data",
    "text": "4.3 Section 4: Fitting Mixed Effect Models to the TLC data\n\nlibrary(tidyr)  #Allows for us to manipulate the data structure\nlibrary(data.table)  #Allows for us to manipulate the data structure\nlibrary(lme4)  #Allows us to fit mixed effects models\nlibrary(lattice)  #for plotting random effects\n\nHere we will learn how to use R to fit Mixed-Effects (subject-specific) Models for longitudinal data, when the outcome of interest is a continuous variable (linear models).\nThe (1|id) means that we are allowing the intercept, represented by 1, to vary by patient.\n\n# label this model object as mod_1\nmod_1 &lt;- lmer(measurements ~ 1 + group + time + (1 | id), data = long_TLC, REML = TRUE)\nsummary(mod_1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: measurements ~ 1 + group + time + (1 | id)\n   Data: long_TLC\n\nREML criterion at convergence: 2670.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4885 -0.3686 -0.0176  0.4514  6.3428 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 22.09    4.700   \n Residual             33.98    5.829   \nNumber of obs: 400, groups:  id, 100\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     25.7647     0.8512  30.269\ngroupTreatment  -5.5775     1.1060  -5.043\ntime            -0.4010     0.1222  -3.281\n\nCorrelation of Fixed Effects:\n            (Intr) grpTrt\ngroupTrtmnt -0.650       \ntime        -0.395  0.000\n\n\n\n# added - some helpful functions\ncoef(mod_1)  # plot all coefficients for each individual\n\n$id\n    (Intercept) groupTreatment   time\n1      27.32695        -5.5775 -0.401\n2      26.75096        -5.5775 -0.401\n3      28.43016        -5.5775 -0.401\n4      24.87134        -5.5775 -0.401\n5      18.44525        -5.5775 -0.401\n6      19.60083        -5.5775 -0.401\n7      23.66160        -5.5775 -0.401\n8      29.42143        -5.5775 -0.401\n9      19.61708        -5.5775 -0.401\n10     29.90894        -5.5775 -0.401\n11     23.35465        -5.5775 -0.401\n12     30.65103        -5.5775 -0.401\n13     23.51715        -5.5775 -0.401\n14     24.43981        -5.5775 -0.401\n15     22.50602        -5.5775 -0.401\n16     22.48797        -5.5775 -0.401\n17     22.88520        -5.5775 -0.401\n18     32.70760        -5.5775 -0.401\n19     33.17886        -5.5775 -0.401\n20     28.80933        -5.5775 -0.401\n21     29.85477        -5.5775 -0.401\n22     28.68294        -5.5775 -0.401\n23     21.20780        -5.5775 -0.401\n24     26.56860        -5.5775 -0.401\n25     24.58426        -5.5775 -0.401\n26     20.53974        -5.5775 -0.401\n27     22.39949        -5.5775 -0.401\n28     22.41574        -5.5775 -0.401\n29     21.80365        -5.5775 -0.401\n30     29.92699        -5.5775 -0.401\n31     28.37599        -5.5775 -0.401\n32     22.65228        -5.5775 -0.401\n33     26.15331        -5.5775 -0.401\n34     24.32967        -5.5775 -0.401\n35     26.18942        -5.5775 -0.401\n36     28.64683        -5.5775 -0.401\n37     29.60199        -5.5775 -0.401\n38     21.51295        -5.5775 -0.401\n39     24.43981        -5.5775 -0.401\n40     34.91223        -5.5775 -0.401\n41     23.80605        -5.5775 -0.401\n42     21.15183        -5.5775 -0.401\n43     21.60503        -5.5775 -0.401\n44     28.28571        -5.5775 -0.401\n45     22.05643        -5.5775 -0.401\n46     29.69227        -5.5775 -0.401\n47     25.75608        -5.5775 -0.401\n48     25.28844        -5.5775 -0.401\n49     23.77174        -5.5775 -0.401\n50     20.86294        -5.5775 -0.401\n51     20.80877        -5.5775 -0.401\n52     22.54213        -5.5775 -0.401\n53     26.67874        -5.5775 -0.401\n54     36.75393        -5.5775 -0.401\n55     28.06724        -5.5775 -0.401\n56     24.52828        -5.5775 -0.401\n57     23.06756        -5.5775 -0.401\n58     21.67545        -5.5775 -0.401\n59     25.26857        -5.5775 -0.401\n60     36.13822        -5.5775 -0.401\n61     29.83671        -5.5775 -0.401\n62     26.89360        -5.5775 -0.401\n63     23.06576        -5.5775 -0.401\n64     20.57585        -5.5775 -0.401\n65     29.09823        -5.5775 -0.401\n66     37.18727        -5.5775 -0.401\n67     30.05338        -5.5775 -0.401\n68     26.15512        -5.5775 -0.401\n69     27.59959        -5.5775 -0.401\n70     23.73563        -5.5775 -0.401\n71     29.80241        -5.5775 -0.401\n72     23.80785        -5.5775 -0.401\n73     29.83671        -5.5775 -0.401\n74     22.79492        -5.5775 -0.401\n75     28.30196        -5.5775 -0.401\n76     24.34772        -5.5775 -0.401\n77     25.14218        -5.5775 -0.401\n78     23.40882        -5.5775 -0.401\n79     20.34112        -5.5775 -0.401\n80     25.30469        -5.5775 -0.401\n81     26.96583        -5.5775 -0.401\n82     25.75789        -5.5775 -0.401\n83     23.19215        -5.5775 -0.401\n84     34.96459        -5.5775 -0.401\n85     26.48012        -5.5775 -0.401\n86     27.00194        -5.5775 -0.401\n87     24.16897        -5.5775 -0.401\n88     23.35465        -5.5775 -0.401\n89     23.30229        -5.5775 -0.401\n90     26.38984        -5.5775 -0.401\n91     20.70224        -5.5775 -0.401\n92     24.65467        -5.5775 -0.401\n93     32.07745        -5.5775 -0.401\n94     23.78980        -5.5775 -0.401\n95     27.14819        -5.5775 -0.401\n96     22.83283        -5.5775 -0.401\n97     28.98989        -5.5775 -0.401\n98     26.58846        -5.5775 -0.401\n99     21.60503        -5.5775 -0.401\n100    24.04258        -5.5775 -0.401\n\nattr(,\"class\")\n[1] \"coef.mer\"\n\nranef(mod_1)  # print random effects, in this case, random intercept\n\n$id\n     (Intercept)\n1    1.562195132\n2    0.986212749\n3    2.665410575\n4   -0.893405269\n5   -7.319497004\n6   -6.163919915\n7   -2.103150120\n8    3.656679165\n9   -6.147669436\n10   4.144188392\n11  -2.410100441\n12   4.886284940\n13  -2.247597426\n14  -1.324941394\n15  -3.258727480\n16  -3.276783010\n17  -2.879553236\n18   6.942851256\n19   7.414109264\n20   3.044584278\n21   4.090020359\n22   2.918193225\n23  -4.556945687\n24   0.803847907\n25  -1.180494305\n26  -5.225013477\n27  -3.365256708\n28  -3.349006572\n29  -3.961101260\n30   4.162244102\n31   2.611242904\n32  -3.112474239\n33   0.388562965\n34  -1.435081807\n35   0.424674204\n36   2.882081443\n37   3.837238252\n38  -4.251801464\n39  -1.324941249\n40   9.147475846\n41  -1.958702995\n42  -4.612919096\n43  -4.159715895\n44   2.520962909\n45  -3.708318629\n46   3.927517705\n47  -0.008666629\n48  -0.476314210\n49  -1.993009202\n50  -4.901813165\n51  -4.955980475\n52  -3.222615157\n53   0.913989006\n54  10.989176327\n55   2.302486647\n56  -1.236467551\n57  -2.697188990\n58  -4.089298087\n59  -0.496175495\n60  10.373469930\n61   4.071963927\n62   1.128854118\n63  -2.698994691\n64  -5.188901695\n65   3.333477986\n66  11.422517160\n67   4.288634795\n68   0.390368539\n69   1.834839066\n70  -2.029120803\n71   4.037658623\n72  -1.956897421\n73   4.071964649\n74  -2.969832689\n75   2.537213405\n76  -1.417026096\n77  -0.622566910\n78  -2.355932408\n79  -5.423628400\n80  -0.460064436\n81   1.201078042\n82  -0.006861163\n83  -2.572602915\n84   9.199837040\n85   0.715374751\n86   1.237189462\n87  -1.595779789\n88  -2.410100261\n89  -2.462462340\n90   0.625094575\n91  -5.062510786\n92  -1.110076137\n93   6.312700659\n94  -1.974952968\n95   1.383442523\n96  -2.931915676\n97   3.225142823\n98   0.823709535\n99  -4.159716093\n100 -1.722170409\n\nwith conditional variances for \"id\" \n\n\n\n# added - some helpful functions\nfixef(mod_1)  # print all fixed effects\n\n   (Intercept) groupTreatment           time \n      25.76475       -5.57750       -0.40100 \n\nAIC(mod_1)  #print model AIC\n\n[1] 2680.185\n\nsummary(ranef(mod_1)$id)  # calculate summary statistics of random intercept\n\n  (Intercept)    \n Min.   :-7.319  \n 1st Qu.:-2.893  \n Median :-0.758  \n Mean   : 0.000  \n 3rd Qu.: 2.625  \n Max.   :11.423  \n\nboxplot(ranef(mod_1)$id)  # create boxplot of estimated random intercept\n\n\n\n\n\n\n\n\n\n# added - some helpful functions\nsummary(resid(mod_1))  # calculate summary statistics of residuals\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-14.5050  -2.1487  -0.1027   0.0000   2.6309  36.9713 \n\nhist(resid(mod_1))  # create histogram to assess distribution of residuals\n\n\n\n\n\n\n\n\n\n# add plot to visualize individual intercepts using dotplot() from the lattice\n# package\ndotplot(ranef(mod_1))\n\n$id\n\n\n\n\n\n\n\n\n\nHere the term (1+time|id) specifies the random intercept and random slope for time.\n\n# label this model object as mod_2\nmod_2 &lt;- lmer(measurements ~ 1 + group + time + (1 + time | id), data = long_TLC,\n    REML = TRUE)\nsummary(mod_2)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: measurements ~ 1 + group + time + (1 + time | id)\n   Data: long_TLC\n\nREML criterion at convergence: 2664.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6833 -0.3869 -0.0118  0.4731  5.8022 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n id       (Intercept) 14.93750 3.8649       \n          time         0.09966 0.3157   1.00\n Residual             33.08488 5.7519       \nNumber of obs: 400, groups:  id, 100\n\nFixed effects:\n               Estimate Std. Error t value\n(Intercept)     25.7370     0.7965  32.312\ngroupTreatment  -5.5220     1.0814  -5.106\ntime            -0.4010     0.1247  -3.217\n\nCorrelation of Fixed Effects:\n            (Intr) grpTrt\ngroupTrtmnt -0.679       \ntime        -0.280  0.000\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nThis model includes time as a continuous covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\n# label this model object as mod_3\nmod_3 &lt;- lmer(measurements ~ 1 + group + time + group:time + (1 | id), data = long_TLC,\n    REML = TRUE)\nsummary(mod_3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: measurements ~ 1 + group + time + group:time + (1 | id)\n   Data: long_TLC\n\nREML criterion at convergence: 2671.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4683 -0.3762 -0.0182  0.4630  6.3507 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 22.06    4.697   \n Residual             34.08    5.838   \nNumber of obs: 400, groups:  id, 100\n\nFixed effects:\n                    Estimate Std. Error t value\n(Intercept)         25.68536    0.91553  28.055\ngroupTreatment      -5.41873    1.29476  -4.185\ntime                -0.37213    0.17310  -2.150\ngroupTreatment:time -0.05774    0.24480  -0.236\n\nCorrelation of Fixed Effects:\n            (Intr) grpTrt time  \ngroupTrtmnt -0.707              \ntime        -0.520  0.368       \ngrpTrtmnt:t  0.368 -0.520 -0.707\n\n\nThis model treats time as a continuous covariate and also introduces a quadratic term.\n\n# label this model object as mod_4\nmod_4 &lt;- lmer(measurements ~ 1 + group + time + time:group + (1 + time | id), data = long_TLC,\n    REML = TRUE)\nsummary(mod_4)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: measurements ~ 1 + group + time + time:group + (1 + time | id)\n   Data: long_TLC\n\nREML criterion at convergence: 2665.3\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6754 -0.3847 -0.0057  0.4880  5.8046 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n id       (Intercept) 14.8608  3.8550       \n          time         0.1017  0.3189   1.00\n Residual             33.1807  5.7603       \nNumber of obs: 400, groups:  id, 100\n\nFixed effects:\n                    Estimate Std. Error t value\n(Intercept)         25.68536    0.82687  31.063\ngroupTreatment      -5.41873    1.16937  -4.634\ntime                -0.37213    0.17665  -2.107\ngroupTreatment:time -0.05774    0.24982  -0.231\n\nCorrelation of Fixed Effects:\n            (Intr) grpTrt time  \ngroupTrtmnt -0.707              \ntime        -0.381  0.269       \ngrpTrtmnt:t  0.269 -0.381 -0.707\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nThis model includes time as a continuous covariate and also includes a quadratic term to capture any possible non-linearity in time and an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\n# label this model object as mod_5\nmod_5 &lt;- lmer(measurements ~ 1 + group + time + I(time^2) + group:(time + I(time^2)) +\n    (1 + time | id) + (I(time^2) | id), data = long_TLC, REML = TRUE)\nsummary(mod_5)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: \nmeasurements ~ 1 + group + time + I(time^2) + group:(time + I(time^2)) +  \n    (1 + time | id) + (I(time^2) | id)\n   Data: long_TLC\n\nREML criterion at convergence: 2547.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7766 -0.4184 -0.0564  0.3925  5.9170 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n id       (Intercept) 16.660   4.0817       \n          time         0.114   0.3377   1.00\n id.1     (Intercept)  0.000   0.0000       \n          I(time^2)    0.000   0.0000    NaN\n Residual             22.056   4.6964       \nNumber of obs: 400, groups:  id, 100\n\nFixed effects:\n                         Estimate Std. Error t value\n(Intercept)              25.96954    0.82515  31.473\ngroupTreatment           -1.99607    1.16693  -1.711\ntime                     -0.91731    0.59637  -1.538\nI(time^2)                 0.09170    0.09721   0.943\ngroupTreatment:time      -6.62390    0.84339  -7.854\ngroupTreatment:I(time^2)  1.10447    0.13747   8.034\n\nCorrelation of Fixed Effects:\n            (Intr) grpTrt time   I(t^2) grpTr:\ngroupTrtmnt -0.707                            \ntime        -0.406  0.287                     \nI(time^2)    0.365 -0.258 -0.969              \ngrpTrtmnt:t  0.287 -0.406 -0.707  0.685       \ngrpTr:I(^2) -0.258  0.365  0.685 -0.707 -0.969\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\n\nmod_5_test &lt;- lmer(measurements ~ 1 + group + time + I(time^2) + group:(time + I(time^2)) +\n    (1 + time + I(time^2) | id), data = long_TLC, REML = TRUE)\nsummary(mod_5_test)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: \nmeasurements ~ 1 + group + time + I(time^2) + group:(time + I(time^2)) +  \n    (1 + time + I(time^2) | id)\n   Data: long_TLC\n\nREML criterion at convergence: 2543\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2531 -0.4033 -0.0512  0.3865  5.2033 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr       \n id       (Intercept) 14.6592  3.8287              \n          time         3.3089  1.8190    0.49      \n          I(time^2)    0.1047  0.3236   -0.28 -0.98\n Residual             19.8761  4.4583              \nNumber of obs: 400, groups:  id, 100\n\nFixed effects:\n                         Estimate Std. Error t value\n(Intercept)               25.9695     0.7788  33.347\ngroupTreatment            -1.9961     1.1014  -1.812\ntime                      -0.9173     0.6202  -1.479\nI(time^2)                  0.0917     0.1030   0.890\ngroupTreatment:time       -6.6239     0.8771  -7.552\ngroupTreatment:I(time^2)   1.1045     0.1457   7.582\n\nCorrelation of Fixed Effects:\n            (Intr) grpTrt time   I(t^2) grpTr:\ngroupTrtmnt -0.707                            \ntime        -0.283  0.200                     \nI(time^2)    0.242 -0.171 -0.972              \ngrpTrtmnt:t  0.200 -0.283 -0.707  0.687       \ngrpTr:I(^2) -0.171  0.242  0.687 -0.707 -0.972\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')"
  },
  {
    "objectID": "Longi_modelselection.html#model-comparison",
    "href": "Longi_modelselection.html#model-comparison",
    "title": "7  Model Selection",
    "section": "7.1 Model Comparison",
    "text": "7.1 Model Comparison\n\nlibrary(tidyr)  #Allows for us to manipulate the data structure\nlibrary(data.table)  #Allows for us to manipulate the data structure\nlibrary(lme4)  #Allows us to fit mixed effects models\nlibrary(lattice)  #for plotting random effects\n\nIn last section, we fit five different mixed effect model on our TLC dataset.\n\n# label this model object as mod_1\nmod_1 &lt;- lmer(measurements ~ 1 + group + time + (1 | id), data = long_TLC, REML = TRUE)\n\n# label this model object as mod_2\nmod_2 &lt;- lmer(measurements ~ 1 + group + time + (1 + time | id), data = long_TLC,\n    REML = TRUE)\n\n# label this model object as mod_3\nmod_3 &lt;- lmer(measurements ~ 1 + group + time + group:time + (1 | id), data = long_TLC,\n    REML = TRUE)\n\n# label this model object as mod_4\nmod_4 &lt;- lmer(measurements ~ 1 + group + time + time:group + (1 + time | id), data = long_TLC,\n    REML = TRUE)\n\n# label this model object as mod_5\nmod_5 &lt;- lmer(measurements ~ 1 + group + time + I(time^2) + group:(time + I(time^2)) +\n    (1 + time | id) + (I(time^2) | id), data = long_TLC, REML = TRUE)\n\nWe are able to compare the models using AIC and BIC. After you write the other models above, run this chunk below.\n\nMixed_Model_comparisons &lt;- data.frame(`Model Name` = c(\"Mixed Model 1\", \"Mixed Model 2\",\n    \"Mixed Model 3\", \"Mixed Model 4\", \"Mixed Model 5\"), AIC = c(AIC(mod_1), AIC(mod_2),\n    AIC(mod_3), AIC(mod_4), AIC(mod_5)), BIC = c(BIC(mod_1), BIC(mod_2), BIC(mod_3),\n    BIC(mod_4), BIC(mod_5)))\nMixed_Model_comparisons\n\n     Model.Name      AIC      BIC\n1 Mixed Model 1 2680.185 2700.143\n2 Mixed Model 2 2678.397 2706.337\n3 Mixed Model 3 2683.108 2707.057\n4 Mixed Model 4 2681.281 2713.213\n5 Mixed Model 5 2573.229 2625.118\n\n\nWhich model would you select?\nAnswer: We would pick Model 5 because it has the lowest AIC and lowest BIC value."
  },
  {
    "objectID": "Longi_mixeffect.html#introduction",
    "href": "Longi_mixeffect.html#introduction",
    "title": "4  Mixed Effects Model",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nLets consider a few simple cases in understanding the Mixed-Effect Model:\n\\[\\mu_{ij} = E(Y_{ij} \\mid {X_{ij},t_{ij}})\\]\nwhere \\(X_{ij}\\) are the explanatory variables and \\(t_{ij}\\) is time.\nIndividual intercepts: The coefficient \\(b_i\\) represents each \\(i\\)th individual starting level.\nConsider the three following cases:\n\n\\(\\mu_{ij} = \\mu + b_i\\)\nModel with only time: \\(\\mu_{ij} = \\beta_0 + \\beta_1 t_{ij} + b_i\\). The systematic component is \\(\\beta_0 + \\beta_1 t_{ij}\\) and random component is \\(b_i\\)\nModel with only covariates: \\(\\mu_{ij} = \\beta_0 + b_i + \\beta_1 X_{ij}\\). The systematic component is \\(\\beta_0 + \\beta_1 X_{ij}\\) and random component is \\(b_i\\)\n\nIn all of these cases (a-c), the coefficient \\(b_i\\) represents the difference between the overall mean intercept and an individual’s intercept. For example, if \\(b_i = -2\\) then the individual \\(i\\) starts at \\(2\\) units lower in their outcome on average.\nIn the Mixed-Effects model, we assume that each individual has their own intercept \\(b_i\\), where \\(b_i \\overset{\\text{iid}}{\\sim} N(0,\\sigma^2_b)\\) and where \\(\\sigma^2_b\\) can be obtained from the summary R output. In addition, we assume that errors have constant variance \\(e_{ij} \\overset{\\text{iid}}{\\sim} N(0,\\sigma^2_e)\\) where \\(\\sigma^2_e\\) can be obtained from the summary R output.\nUsing the TLC data as an example, consider the two models\n\na simple Mixed-Effects model with a random intercept is defined as:\n\n\\[E(y_{ij} \\mid X_{ij}) = \\beta_0 +  \\beta_{trt}trt +  \\beta_{T}T + b_{0,i}\\]\nIndividual slopes: The interpretation of a random slope in the model is that each individual has a unique growth rate or trajectory.\n\na simple Mixed-Effects model with a random intercept and random slope for time is defined as:\n\n\\[E(y_{ij} \\mid X_{ij}) = \\beta_0 +  \\beta_{trt}trt +  \\beta_{T}T + b_{0,i} + b_{T,i}T\\]\nThe systematic component is \\(\\beta_0 + \\beta_{trt}trt + \\beta_{T}T\\) and random component is \\(b_{0,i} + b_{T,i}T\\). Here every \\(i\\)th individual has a unique starting point \\(b_{0,i}\\), hence the average starting point of blood lead levels (BLL) for each individual is \\(\\beta_0 + b_{0,i}\\). Further, each \\(i\\)th individual has a unique growth trajectory of BLL \\(b_{T,i}\\) where the average changes in BLL is given by \\(\\beta_1 + b_{T,i}\\).Thus, the new slope for time is \\((\\beta_{T} + b_{T,i})T\\)\nNote: If the growth rate is explained by explanatory variables (\\(X_{ij}\\)) then include an interaction term. Remember that explanatory variables in the random component of the Mixed-Effects model must be time-varying."
  },
  {
    "objectID": "Longi_noncontinuous.html#background",
    "href": "Longi_noncontinuous.html#background",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.1 Background",
    "text": "10.1 Background\nThe purpose of this lab is to learn how to use R software to fit regression models for longitudinal data when the outcome is non-continuous. We will discuss Marginal and Mixed-Effects models.\nThere are two main types of non-continuous outcomes. The first outcome, which will be the focus of this lab, are binary outcomes where the response variable \\(Y \\in \\{0,1\\}\\). For examples consider the scenarios: Predict whether or not a person will have diabetes or not, predict whether or not a person is positive for COVID-19 or not.\nThe response variable is dichotomous coded with 0’s and 1’s, where observations labeled as 1’s represent the occurrence of an event or outcome of interest. Observations labeled with 0 are labeled as belonging to the negative class, where the event or outcome was not observed.\nHere we only have two options which is usually why it’s a popular approach to build probabilistic models \\(P(Y=1 \\mid X)=g^{-1}(X\\beta)\\) to model the outcome. g is what we call a link function, and common link functions are the logistic link function \\(g(p) = log(\\frac{p}{1-p})\\), the standard normal cumulative density function \\(\\Phi(p)\\), and the complementary log-log function \\(g(p) = log(-log(1-p))\\). log refers to the natural log.\nFor these outcomes, we need to build probabilistic models. Why? Because we cannot use a linear model to estimate the classes. We cannot interpret the output of a linear regression model with these non-continuous outcomes.\nStatisticians prefer probabilistic estimation as it gives us a way to quantify an individual’s level of association to a certain occurrence of event. Probabilities are always bounded between 0 and 1. This boundedness property allows us to know for certain how extreme your estimates are. For instance if your predicted probability is 0.90 then you know there’s an extremely high chance this individual belongs to the positive class. If \\(P(Y=1 \\mid X)\\) is high (e.g. greater than 0.5) then we say it’s more likely that they’re in the positive class than in the negative class. As an aside, but not relevant to the lab, this can also be extended to categorical outcomes where instead of two outcomes there are K outcomes, where \\(K \\ge 2\\) (i.e. multinomial logistic regression). We will not discuss this further.\nAnother type of non-continuous outcome variable takes on discrete values (i.e. integer values like 0,1,2,3,). This is defined as “count data” which represents the number of occurrences of an event within a fixed period. Examples include the number of accidents on a freeway over a year or number of cancer cases in a month. Usually models with count responses are estimated using, though not limited to, Poisson and Negative Binomial distributions.\nThe main rules that we learnt in previous labs for continuous outcomes also apply for non-continuous outcomes. For instance Marginal models for non-continuous outcomes are also population level while Mixed Effect models for non-continuous outcomes are individual (or subject-specific) level.\nAnalogous overall model-selection procedures also remain the same. For instance when doing Maximum Likelihood Estimation we can still use the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) to select our final model. For reference \\(AIC = 2p - 2log(L)\\) where \\(L\\) is the likelihood and p is the number of covariates (excluding the intercept). Similarly \\(BIC = plog(n) - 2log(L)\\) where n is the sample size of the data.\nWhile model comparisons remain the same we need to be careful when intepreting the coefficients that we derive from such models. There is a non-linear relationship being imposed now and we need to adjust our understanding accordlingly. Of course though the above sentence needs some explanation for one to truly grasp what the difference is. In a linear regression \\(y = X^T\\beta\\) so we’d interpret the \\(\\beta\\) in relation to the response. In logistic regression, \\(logit(p) = log(\\frac{p}{1-p}) = X^T\\beta\\) this \\(\\beta\\) represents how a covariate affects the log-odds. An easier way to interpret \\(\\beta\\) in terms of \\(e^\\beta\\) which then tells us how it affects the odds ratio \\(\\frac{p}{1-p}\\)."
  },
  {
    "objectID": "Longi_noncontinuous.html#introduction",
    "href": "Longi_noncontinuous.html#introduction",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.2 Introduction",
    "text": "10.2 Introduction\nIn this lab, we will use data from the “Muscatine Coronary Risk Factor Study” (“muscatine.csv” or “muscatine.dta”). The goal of the study was to examine the development and persistence of risk factors for coronary disease in children. Below we describe our data.\nThe outcome of interest: Obesity status (binary response, “obesity_status”).\nThe data is longitudinal with each subject having at most three measurements. Measurements were taken biannually (every two years) from 1977 to 1981 (i.e. 1977, 1979, 1981). You’ll notice the dataset is already in long format. This is captured in the occasion variable (“1” = 1977, “2” = 1979, “3” = 1981).\nCovariates of interest: Current age (“curr_age”), baseline age (“base_age”) and gender (“gender”). There is also an id variable (“id”) specific to each participant within the study.\nMain Objective: Determine whether the risk of obesity increases with age, and whether the patterns of change in obesity are the same for boys and girls.\n\nWe will use the following packages for models:\n\nlme4: This package is for fitting mixed-effects models. We will use the lmer() function to fit a linear model.\ngeepack: This is the “Generalized Estimating Equation Package” package"
  },
  {
    "objectID": "Longi_noncontinuous.html#loading-the-data-into-rstudio",
    "href": "Longi_noncontinuous.html#loading-the-data-into-rstudio",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.3 Loading the Data into RStudio",
    "text": "10.3 Loading the Data into RStudio\n\nlibrary(tidyr)  # To manipulate the data structure\nlibrary(data.table)  # To manipulate the data structure\nlibrary(ggplot2)  # To create plots\nlibrary(dplyr)  #for dataset manipulations with the %&gt;% operator\nlibrary(scales)  #for making percentages appear on y axis in ggplot\nlibrary(naniar)  #for missing data visualizations\n\n# packages for models\nlibrary(lme4)  # for mixed effects models\nlibrary(geepack)  # install.packages('geepack'), used for the geeglm() function\n\n\n## SLOWEST METHOD: This is in base R (i.e. you odn't need to load any packages)\nmuscatine &lt;- read.csv(\"Data/muscatine.csv\")\n# head function allows us to see a sneak preview of the data.\nhead(muscatine, n = 10)\n\n   id gender base_age curr_age occasion obesity_status\n1   1      0        6        6        1              1\n2   1      0        6        8        2              1\n3   1      0        6       10        3              1\n4   2      0        6        6        1              1\n5   2      0        6        8        2              1\n6   2      0        6       10        3              1\n7   3      0        6        6        1              1\n8   3      0        6        8        2              1\n9   3      0        6       10        3              1\n10  4      0        6        6        1              1\n\n\nBelow we standardize the current age variable by centering by the mean. We also create a label for the gender variable.\n\n# Here we turn muscatine into a data table for easier manipulations\nmuscatine &lt;- data.table(muscatine)\n# Center the variable age (curr_age) around the mean\nmuscatine[, centered_age := curr_age - mean(curr_age)]\n# create labels for gender variable\nmuscatine[, gender_label := ifelse(gender == 0, \"male\", \"female\")]\n\nhead(muscatine, n = 10)\n\n       id gender base_age curr_age occasion obesity_status centered_age\n    &lt;int&gt;  &lt;int&gt;    &lt;int&gt;    &lt;int&gt;    &lt;int&gt;          &lt;int&gt;        &lt;num&gt;\n 1:     1      0        6        6        1              1    -5.976524\n 2:     1      0        6        8        2              1    -3.976524\n 3:     1      0        6       10        3              1    -1.976524\n 4:     2      0        6        6        1              1    -5.976524\n 5:     2      0        6        8        2              1    -3.976524\n 6:     2      0        6       10        3              1    -1.976524\n 7:     3      0        6        6        1              1    -5.976524\n 8:     3      0        6        8        2              1    -3.976524\n 9:     3      0        6       10        3              1    -1.976524\n10:     4      0        6        6        1              1    -5.976524\n    gender_label\n          &lt;char&gt;\n 1:         male\n 2:         male\n 3:         male\n 4:         male\n 5:         male\n 6:         male\n 7:         male\n 8:         male\n 9:         male\n10:         male"
  },
  {
    "objectID": "Longi_noncontinuous.html#exploratory-data-analysis",
    "href": "Longi_noncontinuous.html#exploratory-data-analysis",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.4 Exploratory Data Analysis",
    "text": "10.4 Exploratory Data Analysis\nBefore heading to the model fitting, we first would like to perform some data exploration to have a better understanding. Firstly we will begin with a missing data visualization using the naniar package. The naniar package contains a function called vis_miss which allows us to see which covariates are missing data and by how much. Be sure to install the naniar package first.\n\nvis_miss(muscatine)\n\n\n\n\n\n\n\n\nFrom the above plot we can see that our only missingness is due to the outcome, obesity status.\n\nmuscatine[, numbered_visit := seq_len(.N), by = id]\ndescript &lt;- muscatine %&gt;%\n    group_by(numbered_visit) %&gt;%\n    summarise(ids = length(id), Males = sum(gender_label == \"male\"), Females = sum(gender_label ==\n        \"female\"), mean_age = round(mean(curr_age, na.rm = T), 3), sd = round(sd(curr_age,\n        na.rm = T), 3), var = round(var(curr_age, na.rm = T), 3))\ndescript\n\n# A tibble: 3 × 7\n  numbered_visit   ids Males Females mean_age    sd   var\n           &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1              1  4856  2486    2370     9.98  2.79  7.80\n2              2  4856  2486    2370    12.0   2.79  7.80\n3              3  4856  2486    2370    14.0   2.79  7.80\n\n\nNow we will make barplots to summarize/visualize the proportion of children who are classified as obese within each age within each gender. To start we need to derive this proportion variable. ggplot unfortunately does not have a built in way to specify this so we need to create a new data frame which can take care of this for us. To do so we wil be using the dplyr function.\n\n# by subject, summarize the proportion of these T/F combinations\nobesity_prop_by_age &lt;- muscatine %&gt;%\n    # create a unique identifier for each combination (e.g. 'TRUE-TRUE-FALSE')\ngroup_by(base_age, gender_label) %&gt;%\n    # prop of times each combo type occurs for a given subject:\nreframe(prop = mean(obesity_status, na.rm = T), times = n())\n\nNow that we have the proportions for each age group we create a new variable.\n\nbars &lt;- ggplot(obesity_prop_by_age,\n        aes(x = base_age,y = prop, fill = gender_label)) + \n  geom_bar(stat = \"identity\") +\n  facet_wrap(.~gender_label) + #this is what allows us to make separate boxes for the groups\n  theme(axis.line = element_line(colour = \"black\", linewidth = 2),\n        text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 20, face = \"bold\"),\n        axis.title = element_text(size = 24, face = \"bold\"),\n        axis.ticks.length = unit(.25, \"cm\"),\n        axis.ticks = element_line(colour = \"black\", linewidth = 1.5),\n        strip.background=element_rect(colour = \"black\", fill = \"yellow\")) +\n  ggtitle(\"Proportion of Obese Children by Age and Gender\") +\n  scale_fill_manual(name = \"Gender\", values = c(\"green\",\"purple\")) +\n  scale_y_continuous(labels = percent) +\n  ylab(\"Percent of Obese Children\") +\n  xlab(\"Baseline Age (years)\")\n\nbars\n\n\n\n\n\n\n\n\n\n# by subject, summarize the proportion of these T/F combinations\nobesity_prop_by_curr_age &lt;- muscatine %&gt;%\n    # create a unique identifier for each combination (e.g. 'TRUE-TRUE-FALSE')\ngroup_by(curr_age, gender_label) %&gt;%\n    # prop of times each combo type occurs for a given subject:\nreframe(prop = mean(obesity_status, na.rm = T), times = n())\n\nNow that we have the proportions for each age group we create a new variable.\n\nlines &lt;- ggplot(obesity_prop_by_curr_age,\n                aes(x = curr_age,y = prop,color = gender_label)) + \n  geom_line(linewidth = 3) +\n  facet_wrap(.~gender_label) + #this is what allows us to make separate boxes for the groups\n  theme(axis.line = element_line(colour = \"black\", linewidth = 2),\n        text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 20,face = \"bold\"),\n        axis.title = element_text(size = 24, face = \"bold\"),\n        axis.ticks.length = unit(.25, \"cm\"),\n        axis.ticks = element_line(colour = \"black\", linewidth = 1.5),\n        strip.background=element_rect(colour = \"black\", fill = \"yellow\")) +\n  scale_fill_manual(name = \"Gender\",values = c(\"Female\" = \"green\",\"Male\" = \"purple\")) +\n  scale_y_continuous(labels = percent) +\n  ggtitle(\"Proportion of Obese Children by Age and Gender\") +\n  ylab(\"Percent of Obese Children\") +\n  xlab(\"Baseline Age (years)\")\n\nlines"
  },
  {
    "objectID": "Longi_noncontinuous.html#marginal-models",
    "href": "Longi_noncontinuous.html#marginal-models",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.5 Marginal Models",
    "text": "10.5 Marginal Models\nModel 1: This model includes gender, age, age\\(^2\\), and an interaction term.\nModel 1: \\(E(y_{ij} \\mid X) = beta_{0} + \\beta_{age}age + \\beta_{age^2}age^2 + \\beta_{gender}gender + \\beta_{gender:age}gender*age + \\beta_{gender:age^2}gender*age^2\\).\n\nmodel_1 &lt;- geeglm(obesity_status ~ 1 + gender + centered_age + I(centered_age^2) +\n    centered_age:gender + I(centered_age^2):gender, id = id, data = muscatine, family = binomial(link = \"logit\"),\n    corstr = \"unstructured\")\nsummary(model_1)\n\n\nCall:\ngeeglm(formula = obesity_status ~ 1 + gender + centered_age + \n    I(centered_age^2) + centered_age:gender + I(centered_age^2):gender, \n    family = binomial(link = \"logit\"), data = muscatine, id = id, \n    corstr = \"unstructured\")\n\n Coefficients:\n                          Estimate   Std.err    Wald Pr(&gt;|W|)    \n(Intercept)              -1.210629  0.050581 572.862  &lt; 2e-16 ***\ngender                    0.112872  0.071127   2.518  0.11253    \ncentered_age              0.040922  0.013348   9.398  0.00217 ** \nI(centered_age^2)        -0.017927  0.003388  28.002 1.21e-07 ***\ngender:centered_age       0.005087  0.018349   0.077  0.78161    \ngender:I(centered_age^2)  0.003883  0.004642   0.700  0.40295    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)   0.9925 0.02745\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2   0.5792 0.02042\nalpha.1:3   0.4624 0.03192\nalpha.2:3   0.5589 0.03207\nNumber of clusters:   4856  Maximum cluster size: 3 \n\n\nModel 2: This model includes gender, age, age\\(^2\\), and no interaction term.\nModel 2: \\(E(y_{ij} \\mid X) = beta_{0} + \\beta_{age}age + \\beta_{age^2}age^2 + \\beta_{gender}gender\\).\n\nmodel_2 &lt;- geeglm(obesity_status ~ gender + centered_age + I(centered_age^2), id = id,\n    data = muscatine, family = binomial(link = \"logit\"), corstr = \"unstructured\")\nsummary(model_2)\n\n\nCall:\ngeeglm(formula = obesity_status ~ gender + centered_age + I(centered_age^2), \n    family = binomial(link = \"logit\"), data = muscatine, id = id, \n    corstr = \"unstructured\")\n\n Coefficients:\n                  Estimate  Std.err  Wald Pr(&gt;|W|)    \n(Intercept)       -1.22520  0.04772 659.3  &lt; 2e-16 ***\ngender             0.14152  0.06270   5.1    0.024 *  \ncentered_age       0.04368  0.00915  22.8  1.8e-06 ***\nI(centered_age^2) -0.01593  0.00231  47.4  5.8e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)    0.992  0.0274\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.580  0.0204\nalpha.1:3    0.462  0.0319\nalpha.2:3    0.558  0.0320\nNumber of clusters:   4856  Maximum cluster size: 3 \n\n\nNow that we have our two models what do we do with them? As mentioned before the purpose is to predict probabilities so let’s do just that. This can be done through the predict() function. To return predicted probabilities specify type as “response”. To get back the linear predictions (i.e. the natural log of the odds ratio \\(\\frac{P(Y=1| \\mid X)}{1-P(Y=1 \\mid X)}\\) in this case) specify type as “link” (i.e. for link function). A third option is to specify type as “terms”. This gives you back an \\(N \\times (p-1)\\) matrix where each column corresponds to the product of the estimated coefficient \\(\\beta_j\\) and the corresponding covariate \\(X_j\\). This is not done for the intercept so that must be done manually.\n\n# calculate predicted probabilities for model 1\nmodel_1_probs &lt;- predict(model_1, type = \"response\")\n\n# calculate predicted probabilities for model 2\nmodel_2_probs &lt;- predict(model_2, type = \"response\")\n\nNow that we have these two probability vectors what do we do with them? We can see how these probabilities vary with respect to age and gender.\nWe can create plots. We will take the predicted probabilities and plot them against the observed. To do so we begin by taking the mean predicted probability within each Age/Gender strata. To make that clearer, for example we look at the predicted probabilities for all 14 year old males and find their mean.\nNote: Uncomment this after you defined model_2_probs\n\n#create new dataset that removes missing values\nmuscatine_complete &lt;- na.omit(muscatine)\n\n# add in probabilities as covariates\nmuscatine_complete[,model_1 := model_1_probs]\nmuscatine_complete[,model_2 := model_2_probs]\n\n# by subject, summarize the proportion of these T/F combinations \ngee_probs &lt;- data.table(muscatine_complete %&gt;%\n  # create a unique identifier for each combination (e.g. \"TRUE-TRUE-FALSE\")\n  group_by(curr_age, gender_label) %&gt;%\n  # prop of times each combo type occurs for a given subject:\n  reframe(prop = mean(obesity_status, na.rm = T),\n          prob_1 = mean(model_1),\n          prob_2 = mean(model_2)))\n\ndf_models &lt;- data.frame(\"Age\" = unique(gee_probs[, curr_age]),\n                    \"Est_Female1\" = gee_probs[gender_label == \"female\", prob_1],\n                    \"Est_Male1\" = gee_probs[gender_label == \"male\", prob_1],\n                    \"Est_Female2\" = gee_probs[gender_label == \"female\", prob_2],\n                    \"Est_Male2\" = gee_probs[gender_label == \"male\", prob_2],\n                     \"Obs_Female\" = gee_probs[gender_label == \"female\", prop],\n                     \"Obs_Male\" = gee_probs[gender_label == \"male\", prop])\n\n\nlabels &lt;- c(\"Est. Probability, Female\", \"Est. Probability, Male\", \"Obs. Proportion, Female\",\n    \"Obs. Proportion, Male\")\ndf &lt;- data.frame(x = rep(df_models[, \"Age\"], times = 4), y = c(df_models[, \"Est_Female1\"],\n    df_models[, \"Est_Male1\"], df_models[, \"Obs_Female\"], df_models[, \"Obs_Male\"]),\n    group = rep(labels, each = 7))\n\ndf %&gt;%\n    ggplot() + geom_line(aes(x, y, color = group, linetype = group), linewidth = 2) +\n    theme(axis.line = element_line(colour = \"black\", linewidth = 2), text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 20, face = \"bold\"), axis.title = element_text(size = 24,\n            face = \"bold\"), axis.ticks.length = unit(0.25, \"cm\"), axis.ticks = element_line(colour = \"black\",\n            linewidth = 1.5)) + scale_color_manual(name = \"\", labels = labels, values = c(\"darkred\",\n    \"darkblue\", \"red\", \"dodgerblue3\")) + scale_linetype_manual(name = \"\", labels = labels,\n    values = c(\"dashed\", \"dashed\", \"solid\", \"solid\")) + scale_y_continuous(labels = percent) +\n    ggtitle(\"Marginal Model 1: Observed vs Predicted Probabilities\") + ylab(\"Percent of Obese Children\") +\n    xlab(\"Age (years)\")\n\n\n\n\n\n\n\n\n\ndf &lt;- data.frame(x = rep(df_models[, \"Age\"], times = 4), y = c(df_models[, \"Est_Female2\"],\n    df_models[, \"Est_Male2\"], df_models[, \"Obs_Female\"], df_models[, \"Obs_Male\"]),\n    group = rep(labels, each = 7))\n\ndf %&gt;%\n    ggplot() + geom_line(aes(x, y, color = group, linetype = group), linewidth = 2) +\n    theme(axis.line = element_line(colour = \"black\", linewidth = 2), text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 20, face = \"bold\"), axis.title = element_text(size = 24,\n            face = \"bold\"), axis.ticks.length = unit(0.25, \"cm\"), axis.ticks = element_line(colour = \"black\",\n            linewidth = 1.5)) + scale_color_manual(name = \" \", labels = labels, values = c(\"darkred\",\n    \"darkblue\", \"red\", \"dodgerblue3\")) + scale_linetype_manual(name = \" \", labels = labels,\n    values = c(\"dashed\", \"dashed\", \"solid\", \"solid\")) + scale_y_continuous(labels = percent) +\n    ggtitle(\"Marginal Model 2: Observed vs Predicted Probabilities\") + ylab(\"Percent of Obese Children\") +\n    xlab(\"Age (years)\")"
  },
  {
    "objectID": "Longi_noncontinuous.html#mixed-effect-models",
    "href": "Longi_noncontinuous.html#mixed-effect-models",
    "title": "10  Models for Non-Continuous Outcomes",
    "section": "10.6 Mixed Effect Models",
    "text": "10.6 Mixed Effect Models\nIn this section we will fit Mixed-Effects (subject-specific) Models for longitudinal data, when the outcome of interest is a non-continuous variable.\nRecall that a Generalized Mixed Effects Model has the following form: \\(g(E[y_{ij} \\mid X] )= X_{i}\\beta + Z_{i}b_i\\). Here \\(g(p) = logit(p)\\).\nModel 3: We fit a mixed-effects model with gender, age, age\\(^2\\), and an interaction term, and a random intercept.\nModel 3: \\(logit(E[y_{i} \\mid b_i, X_i, \\beta])= beta_{0} + \\beta_{age}age + \\beta_{age^2}age^2 + \\beta_{gender}gender + \\beta_{gender:age}gender*age + \\beta_{gender:age^2}gender*age^2 + b_{0,i}\\).\nThe (1|id) means that we are allowing the intercept, represented by 1, to vary by patient.\n\nmodel_3 &lt;- glmer(obesity_status ~ 1 + gender + centered_age + I(centered_age^2) +\n    centered_age:gender + I(centered_age^2):gender + (1 | id), family = binomial(link = \"logit\"),\n    data = muscatine, nAGQ = 7)\nsummary(model_3)\n\nGeneralized linear mixed model fit by maximum likelihood (Adaptive\n  Gauss-Hermite Quadrature, nAGQ = 7) [glmerMod]\n Family: binomial  ( logit )\nFormula: obesity_status ~ 1 + gender + centered_age + I(centered_age^2) +  \n    centered_age:gender + I(centered_age^2):gender + (1 | id)\n   Data: muscatine\n\n     AIC      BIC   logLik deviance df.resid \n    8729     8780    -4358     8715     9849 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.546 -0.192 -0.174 -0.115  2.522 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 9.91     3.15    \nNumber of obs: 9856, groups:  id, 4856\n\nFixed effects:\n                         Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -2.70752    0.12459  -21.73  &lt; 2e-16 ***\ngender                    0.25270    0.15134    1.67   0.0950 .  \ncentered_age              0.08330    0.02710    3.07   0.0021 ** \nI(centered_age^2)        -0.03785    0.00688   -5.50  3.7e-08 ***\ngender:centered_age       0.01719    0.03795    0.45   0.6506    \ngender:I(centered_age^2)  0.00807    0.00959    0.84   0.3998    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) gender cntrd_ I(_^2) gndr:_\ngender      -0.635                            \ncentered_ag -0.033 -0.008                     \nI(cntrd_^2) -0.349  0.336 -0.041              \ngndr:cntrd_ -0.024  0.013 -0.705  0.017       \ngndr:I(_^2)  0.286 -0.486  0.023 -0.708 -0.043\n\n\nOne thing you might notice about the glmer() function and its output are integration points and the parameter nAGQ, which specifies said points. When the distribution we’re dealing with isn’t normal and the link function \\(g()\\) isn’t the identity we can’t derive an analytic solution.\nIn fact the log likelihood \\(\\ell(\\beta)\\) looks like: \\(\\ell(\\beta) = \\sum^N_{i=1}log( p(y_j \\mid \\beta) ) = \\sum^N_{i=1}log( \\int p(y_j \\mid b_j,X_j, \\beta)p(b_j \\mid \\beta) db_j)\\)\nThe integral in the definition does not have a closed-form solution, and numerical approximations are required to obtain the maximum likelihood estimates. So when you see the word Adaptive Gauss-Hermite Quadrature that is simply the method that we use to approximate the integral.\nFor those who are curious, Gauss-Hermite Quadrature is a method for approximating integrals of the following form: \\(\\int e^{-x^2} f(x)dx \\approx \\sum^K_{k=1}w_k f(x_k)\\) where we pick k points (i.e. the integration points). The \\(x_k\\) are the roots of the \\(K^{th}\\) order Hermite polynomial \\(H_K(x)\\) where \\(H_K(x) = (-1)^K e^{x^2} \\frac{d^K}{dx^K}e^{-x^2}\\), and \\(w_k = \\frac{2^{K-1}K!\\sqrt{\\pi}}{K^2[H_{K-1}(x_k)]^2}\\). Adaptive Gauss Qudrature chooses the integration points \\(x_k\\) through a different method, but the specification of the weights \\(w_k\\) remains the same.\nFor \\(K=1\\) this is just the Laplace Approximation method for integration which glmer() uses automatically. If you want to use Adaptive Gauss Hermite you need to specify nAGQ &gt; 1. I mention this because STATA uses adaptive and non-adaptive Gauss Hermite Quadrature to estimate the integral.\nModel 4: We fit a mixed-effects model with gender, age, age\\(^2\\), with no interaction term, and a random intercept.\nModel 4: \\(logit(E[y_{i} \\mid b_i, X_i, \\beta]) = beta_{0} + \\beta_{age}age + \\beta_{age^2}age^2 + b_{0,i}\\).\n\n# name this model 'model_4'\n\nmodel_4 &lt;- glmer(obesity_status ~ 1 + gender + centered_age + I(centered_age^2) +\n    (1 | id), data = muscatine, family = binomial(link = \"logit\"), nAGQ = 7)\nsummary(model_4)\n\nGeneralized linear mixed model fit by maximum likelihood (Adaptive\n  Gauss-Hermite Quadrature, nAGQ = 7) [glmerMod]\n Family: binomial  ( logit )\nFormula: obesity_status ~ 1 + gender + centered_age + I(centered_age^2) +  \n    (1 | id)\n   Data: muscatine\n\n     AIC      BIC   logLik deviance df.resid \n    8726     8762    -4358     8716     9851 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-1.545 -0.193 -0.170 -0.116  2.602 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 9.9      3.15    \nNumber of obs: 9856, groups:  id, 4856\n\nFixed effects:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -2.73777    0.11948  -22.91  &lt; 2e-16 ***\ngender             0.31539    0.13218    2.39    0.017 *  \ncentered_age       0.09211    0.01921    4.80  1.6e-06 ***\nI(centered_age^2) -0.03375    0.00485   -6.96  3.5e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) gender cntrd_\ngender      -0.594              \ncentered_ag -0.072 -0.001       \nI(cntrd_^2) -0.219 -0.010 -0.068\n\n\n\n# calculate predicted probabilities for model 3\nmodel_3_probs &lt;- predict(model_3, type = \"response\")\n\n# calculate predicted probabilities for model 4\nmodel_4_probs &lt;- predict(model_4, type = \"response\")\n\nNote: Uncomment this after you define model_3_probs and model_4_probs\n\n# add in probabilities as covariates\nmuscatine_complete[, model_3 := model_3_probs]\nmuscatine_complete[, model_4 := model_4_probs]\n\n\n# by subject, summarize the proportion of these T/F combinations \nmem_probs &lt;- data.table( muscatine_complete %&gt;%\n  # create a unique identifier for each combination (e.g. \"TRUE-TRUE-FALSE\")\n  group_by(curr_age, gender_label) %&gt;%\n  # prop of times each combo type occurs for a given subject:\n  reframe(prob_3 = max(model_3),\n          prob_4 = max(model_4)))\ndf_models2 &lt;- cbind(df_models, data.frame(\"Est_Female3\" = mem_probs[gender_label == \"female\", prob_3],\n                                          \"Est_Male3\" = mem_probs[gender_label == \"male\", prob_3],\n                                          \"Est_Female4\" = mem_probs[gender_label == \"female\", prob_4],\n                                          \"Est_Male4\" = mem_probs[gender_label == \"male\", prob_4]))\ndf_models2 &lt;- as.data.frame(df_models2)\n\n\ndf &lt;- data.frame(x = rep(df_models[, \"Age\"], times = 4), y = c(df_models2[, \"Est_Female3\"],\n    df_models2[, \"Est_Male3\"], df_models2[, \"Obs_Female\"], df_models2[, \"Obs_Male\"]),\n    group = rep(labels, each = 7))\n\ndf %&gt;%\n    ggplot() + geom_line(aes(x, y, color = group, linetype = group), linewidth = 2) +\n    theme(axis.line = element_line(colour = \"black\", linewidth = 2), text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 20, face = \"bold\"), axis.title = element_text(size = 24,\n            face = \"bold\"), axis.ticks.length = unit(0.25, \"cm\"), axis.ticks = element_line(colour = \"black\",\n            linewidth = 1.5)) + scale_color_manual(name = \"\", labels = labels, values = c(\"darkred\",\n    \"darkblue\", \"red\", \"dodgerblue3\")) + scale_linetype_manual(name = \"\", labels = labels,\n    values = c(\"dashed\", \"dashed\", \"solid\", \"solid\")) + scale_y_continuous(labels = percent) +\n    ggtitle(\"Mixed Effect Model 1: Observed vs Predicted Probabilities\") + ylab(\"Percent of Obese Children\") +\n    xlab(\"Baseline Age (years)\")\n\n\n\n\n\n\n\n\n\ndf &lt;- data.frame(x = rep(df_models[, \"Age\"], times = 4), y = c(df_models2[, \"Est_Female4\"],\n    df_models2[, \"Est_Male4\"], df_models2[, \"Obs_Female\"], df_models2[, \"Obs_Male\"]),\n    group = rep(labels, each = 7))\n\ndf %&gt;%\n    ggplot() + geom_line(aes(x, y, color = group, linetype = group), linewidth = 2) +\n    theme(axis.line = element_line(colour = \"black\", linewidth = 2), text = element_text(size = 20),\n        axis.text = element_text(colour = \"black\", size = 20, face = \"bold\"), axis.title = element_text(size = 24,\n            face = \"bold\"), axis.ticks.length = unit(0.25, \"cm\"), axis.ticks = element_line(colour = \"black\",\n            linewidth = 1.5)) + scale_color_manual(name = \" \", labels = labels, values = c(\"darkred\",\n    \"darkblue\", \"red\", \"dodgerblue3\")) + scale_linetype_manual(name = \" \", labels = labels,\n    values = c(\"dashed\", \"dashed\", \"solid\", \"solid\")) + scale_y_continuous(labels = percent) +\n    ggtitle(\"Mixed Effect Model 2: Observed vs Predicted Probabilities\") + ylab(\"Percent of Obese Children\") +\n    xlab(\"Baseline Age (years)\")"
  },
  {
    "objectID": "Longi_covmodel.html",
    "href": "Longi_covmodel.html",
    "title": "6  Modeling the Covariance",
    "section": "",
    "text": "library(tidyr)  #Allows for us to manipulate the data structure\nlibrary(data.table)  #Allows for us to manipulate the data structure\nlibrary(lme4)  #Allows us to fit mixed effects models\nlibrary(lattice)  #for plotting random effects\nlibrary(nlme)\n\nRecall (from notes): Using the gls() function to fit a linear model using generalized least squares. The syntax for the function gls() in nlme package is\ngls(model, data, correlation, weights, subset, method, na.action, control, verbose)\n\nDescription\n\nmodel: A two-sided linear formula object describing the model\ndata: Optional dataframe\ncorrelation: See description for details.\n\nThe corStruct object describes the within-group correlation structure.\nNote we use corCompSymm which has the following syntax: corCompSymm(value, form, fixed) compound symmetry structure corresponding to a constant correlation.\n\nweights: See description for details.\n\nDescribes the variance function.\nNote we use varClasses which defines standard classes of variance function structures and use “varIdent” which describes constant variance(s), that is generally used to allow different variances.\n\n\n\nModel 1: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T_1}T_1 + \\beta_{T_4}T_4 + \\beta_{T_6}T_6 + \\beta_{trt:T_1}trt*T_1 + \\beta_{trt:T_4}trt*T_4 + \\beta_{trt:T_6}trt*T_6\\).\nThis model includes time as a categorical covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\n# unstructured covariance\nmod_1_unstruc &lt;- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level),\n    data = long_TLC, corr = corSymm(form = ~1 | id), weights = varIdent(form = ~1 |\n        as.factor(level)), method = \"REML\")\nsummary(mod_1_unstruc)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + factor(level) + factor(group):factor(level) \n  Data: long_TLC \n       AIC      BIC    logLik\n  2452.076 2523.559 -1208.038\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1     2     3    \n2 0.571            \n3 0.570 0.775      \n4 0.577 0.582 0.581\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | as.factor(level) \n Parameter estimates:\n   lead0    lead1    lead4    lead6 \n1.000000 1.325881 1.370473 1.524828 \n\nCoefficients:\n                                            Value Std.Error   t-value p-value\n(Intercept)                                26.272 0.7102870  36.98787  0.0000\nfactor(group)Treatment                      0.268 1.0044975   0.26680  0.7898\nfactor(level)lead1                         -1.612 0.7919161  -2.03557  0.0425\nfactor(level)lead4                         -2.202 0.8149208  -2.70210  0.0072\nfactor(level)lead6                         -2.626 0.8885227  -2.95547  0.0033\nfactor(group)Treatment:factor(level)lead1 -11.406 1.1199385 -10.18449  0.0000\nfactor(group)Treatment:factor(level)lead4  -8.824 1.1524721  -7.65658  0.0000\nfactor(group)Treatment:factor(level)lead6  -3.152 1.2565608  -2.50843  0.0125\n\n Correlation: \n                                          (Intr) fct()T fct()1 fct()4 fct()6\nfactor(group)Treatment                    -0.707                            \nfactor(level)lead1                        -0.218  0.154                     \nfactor(level)lead4                        -0.191  0.135  0.680              \nfactor(level)lead6                        -0.096  0.068  0.386  0.385       \nfactor(group)Treatment:factor(level)lead1  0.154 -0.218 -0.707 -0.481 -0.273\nfactor(group)Treatment:factor(level)lead4  0.135 -0.191 -0.481 -0.707 -0.272\nfactor(group)Treatment:factor(level)lead6  0.068 -0.096 -0.273 -0.272 -0.707\n                                          f()T:()1 f()T:()4\nfactor(group)Treatment                                     \nfactor(level)lead1                                         \nfactor(level)lead4                                         \nfactor(level)lead6                                         \nfactor(group)Treatment:factor(level)lead1                  \nfactor(group)Treatment:factor(level)lead4  0.680           \nfactor(group)Treatment:factor(level)lead6  0.386    0.385  \n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.1756425 -0.6849970 -0.1515552  0.5294183  5.6327493 \n\nResidual standard error: 5.022487 \nDegrees of freedom: 400 total; 392 residual\n\n\n\n# exchangeable (constant variances)\nmod_1_exch_const &lt;- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level),\n    data = long_TLC, corr = corCompSymm(form = ~factor(level) | id), weights = varIdent(form = ~1),\n    method = \"REML\")\n\nsummary(mod_1_exch_const)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + factor(level) + factor(group):factor(level) \n  Data: long_TLC \n       AIC      BIC    logLik\n  2480.621 2520.334 -1230.311\n\nCorrelation Structure: Compound symmetry\n Formula: ~factor(level) | id \n Parameter estimate(s):\n      Rho \n0.5954401 \n\nCoefficients:\n                                            Value Std.Error   t-value p-value\n(Intercept)                                26.272 0.9370175 28.037898  0.0000\nfactor(group)Treatment                      0.268 1.3251428  0.202242  0.8398\nfactor(level)lead1                         -1.612 0.8428574 -1.912542  0.0565\nfactor(level)lead4                         -2.202 0.8428574 -2.612541  0.0093\nfactor(level)lead6                         -2.626 0.8428574 -3.115592  0.0020\nfactor(group)Treatment:factor(level)lead1 -11.406 1.1919804 -9.568950  0.0000\nfactor(group)Treatment:factor(level)lead4  -8.824 1.1919804 -7.402807  0.0000\nfactor(group)Treatment:factor(level)lead6  -3.152 1.1919804 -2.644339  0.0085\n\n Correlation: \n                                          (Intr) fct()T fct()1 fct()4 fct()6\nfactor(group)Treatment                    -0.707                            \nfactor(level)lead1                        -0.450  0.318                     \nfactor(level)lead4                        -0.450  0.318  0.500              \nfactor(level)lead6                        -0.450  0.318  0.500  0.500       \nfactor(group)Treatment:factor(level)lead1  0.318 -0.450 -0.707 -0.354 -0.354\nfactor(group)Treatment:factor(level)lead4  0.318 -0.450 -0.354 -0.707 -0.354\nfactor(group)Treatment:factor(level)lead6  0.318 -0.450 -0.354 -0.354 -0.707\n                                          f()T:()1 f()T:()4\nfactor(group)Treatment                                     \nfactor(level)lead1                                         \nfactor(level)lead4                                         \nfactor(level)lead6                                         \nfactor(group)Treatment:factor(level)lead1                  \nfactor(group)Treatment:factor(level)lead4  0.500           \nfactor(group)Treatment:factor(level)lead6  0.500    0.500  \n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.5147478 -0.6973588 -0.1498707  0.5542798  6.5106947 \n\nResidual standard error: 6.625714 \nDegrees of freedom: 400 total; 392 residual\n\n\n\n# exchangeable (heterogeneous variances)\nmod_1_exch_heter &lt;- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level),\n    data = long_TLC, corr = corCompSymm(form = ~factor(level) | id), weights = varIdent(form = ~1 |\n        factor(level)), method = \"REML\")\n\nsummary(mod_1_exch_heter)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + factor(level) + factor(group):factor(level) \n  Data: long_TLC \n      AIC      BIC   logLik\n  2459.96 2511.587 -1216.98\n\nCorrelation Structure: Compound symmetry\n Formula: ~factor(level) | id \n Parameter estimate(s):\n      Rho \n0.6102726 \nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | factor(level) \n Parameter estimates:\n   lead0    lead1    lead4    lead6 \n1.000000 1.279673 1.323194 1.519223 \n\nCoefficients:\n                                            Value Std.Error   t-value p-value\n(Intercept)                                26.272 0.7237961  36.29751  0.0000\nfactor(group)Treatment                      0.268 1.0236023   0.26182  0.7936\nfactor(level)lead1                         -1.612 0.7506795  -2.14739  0.0324\nfactor(level)lead4                         -2.202 0.7713861  -2.85460  0.0045\nfactor(level)lead6                         -2.626 0.8726947  -3.00907  0.0028\nfactor(group)Treatment:factor(level)lead1 -11.406 1.0616211 -10.74395  0.0000\nfactor(group)Treatment:factor(level)lead4  -8.824 1.0909047  -8.08870  0.0000\nfactor(group)Treatment:factor(level)lead6  -3.152 1.2341767  -2.55393  0.0110\n\n Correlation: \n                                          (Intr) fct()T fct()1 fct()4 fct()6\nfactor(group)Treatment                    -0.707                            \nfactor(level)lead1                        -0.211  0.149                     \nfactor(level)lead4                        -0.181  0.128  0.402              \nfactor(level)lead6                        -0.060  0.043  0.383  0.383       \nfactor(group)Treatment:factor(level)lead1  0.149 -0.211 -0.707 -0.285 -0.270\nfactor(group)Treatment:factor(level)lead4  0.128 -0.181 -0.285 -0.707 -0.271\nfactor(group)Treatment:factor(level)lead6  0.043 -0.060 -0.270 -0.271 -0.707\n                                          f()T:()1 f()T:()4\nfactor(group)Treatment                                     \nfactor(level)lead1                                         \nfactor(level)lead4                                         \nfactor(level)lead6                                         \nfactor(group)Treatment:factor(level)lead1                  \nfactor(group)Treatment:factor(level)lead4  0.402           \nfactor(group)Treatment:factor(level)lead6  0.383    0.383  \n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.1429121 -0.6927784 -0.1528884  0.5263114  5.5480102 \n\nResidual standard error: 5.118012 \nDegrees of freedom: 400 total; 392 residual"
  },
  {
    "objectID": "Longi_modelselection.html#comparing-mean-models",
    "href": "Longi_modelselection.html#comparing-mean-models",
    "title": "7  Model Selection",
    "section": "7.1 Comparing Mean Models",
    "text": "7.1 Comparing Mean Models\nIn this section, we will apply the backward selection method to\nMod_base: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T + \\beta_{T^2}T^2 + \\beta_{trt:T}trt*T+\\beta_{trt:T^2}trt*T^2\\).\n\n# start off with baseline model including all terms\nmod_base_unstruc &lt;- gls(measurements ~ factor(group) + time + I(time^2) + factor(group):(time +\n    I(time^2)), data = long_TLC, corr = corSymm(form = ~1 | id), weights = varIdent(form = ~1 |\n    time), method = \"REML\")\n\nsummary(mod_base_unstruc)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + time + I(time^2) + factor(group):(time +      I(time^2)) \n  Data: long_TLC \n       AIC     BIC    logLik\n  2551.458 2615.08 -1259.729\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1     2     3    \n2 0.383            \n3 0.554 0.674      \n4 0.479 0.645 0.561\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | time \n Parameter estimates:\n       0        1        4        6 \n1.000000 1.559262 1.353064 1.599958 \n\nCoefficients:\n                                     Value Std.Error  t-value p-value\n(Intercept)                      26.131925 0.7026919 37.18831  0.0000\nfactor(group)Treatment           -0.780537 0.9937564 -0.78544  0.4327\ntime                             -0.833455 0.5657089 -1.47329  0.1415\nI(time^2)                         0.082736 0.0983326  0.84138  0.4006\nfactor(group)Treatment:time      -5.996169 0.8000332 -7.49490  0.0000\nfactor(group)Treatment:I(time^2)  1.037345 0.1390632  7.45952  0.0000\n\n Correlation: \n                                 (Intr) fct()T time   I(t^2) fc()T:\nfactor(group)Treatment           -0.707                            \ntime                             -0.169  0.119                     \nI(time^2)                         0.156 -0.110 -0.976              \nfactor(group)Treatment:time       0.119 -0.169 -0.707  0.690       \nfactor(group)Treatment:I(time^2) -0.110  0.156  0.690 -0.707 -0.976\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.5279799 -0.7879764 -0.2643423  0.4368115  4.8117579 \n\nResidual standard error: 5.092277 \nDegrees of freedom: 400 total; 394 residual\n\n\n\n# If there were higher order terms that were significant we would remove them,\n# but in this case both interaction terms are significant so we want to keep\n# them in the model\n\n# However, suppose the quadratic terms were not significant, lets remove them\n# here in this example\nmod_second_unstruc &lt;- gls(measurements ~ factor(group) + time + factor(group):(time),\n    data = long_TLC, corr = corSymm(form = ~1 | id), weights = varIdent(form = ~1 |\n        time), method = \"REML\")\n\nsummary(mod_second_unstruc)\n\nGeneralized least squares fit by REML\n  Model: measurements ~ factor(group) + time + factor(group):(time) \n  Data: long_TLC \n       AIC      BIC    logLik\n  2586.646 2642.386 -1279.323\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1     2     3    \n2 0.132            \n3 0.271 0.846      \n4 0.543 0.406 0.495\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | time \n Parameter estimates:\n       0        1        4        6 \n1.000000 1.833984 1.551842 1.439514 \n\nCoefficients:\n                                Value Std.Error  t-value p-value\n(Intercept)                 26.039582 0.6940593 37.51780  0.0000\nfactor(group)Treatment      -1.938410 0.9815481 -1.97485  0.0490\ntime                        -0.368743 0.1223416 -3.01404  0.0027\nfactor(group)Treatment:time -0.169559 0.1730172 -0.98001  0.3277\n\n Correlation: \n                            (Intr) fct()T time  \nfactor(group)Treatment      -0.707              \ntime                        -0.077  0.054       \nfactor(group)Treatment:time  0.054 -0.077 -0.707\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.2991338 -0.7973523 -0.2854753  0.3570825  5.6284768 \n\nResidual standard error: 5.310688 \nDegrees of freedom: 400 total; 396 residual\n\n\nNote that all terms are now significant, including the interaction term. We used the backwards selection method to obtain the “best” model. Suppose we wanted to compare the mean models of mod_base_unstruc and mod_second_unstruc. We can compare model means using anova()\n\nanova(mod_base_unstruc, mod_second_unstruc)\n\n                   Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nmod_base_unstruc       1 16 2551.458 2615.080 -1259.729                        \nmod_second_unstruc     2 14 2586.646 2642.386 -1279.323 1 vs 2 39.18782  &lt;.0001\n\n\nBased on these results, which is the best model?\nAnswer: The model called “mod_base_unstruc” is the best model which is consistent with our previous results"
  },
  {
    "objectID": "Longi_modelselection.html#comparing-covariance-models",
    "href": "Longi_modelselection.html#comparing-covariance-models",
    "title": "7  Model Selection",
    "section": "7.2 Comparing Covariance Models",
    "text": "7.2 Comparing Covariance Models\nIn previous section, we fit three models on our data using various covariance structure below:\n\n# unstructured covariance\nmod_1_unstruc &lt;- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level),\n    data = long_TLC, corr = corSymm(form = ~1 | id), weights = varIdent(form = ~1 |\n        as.factor(level)), method = \"REML\")\n\n# exchangeable (constant variances)\nmod_1_exch_const &lt;- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level),\n    data = long_TLC, corr = corCompSymm(form = ~factor(level) | id), weights = varIdent(form = ~1),\n    method = \"REML\")\n\n# exchangeable (heterogeneous variances)\nmod_1_exch_heter &lt;- gls(measurements ~ factor(group) + factor(level) + factor(group):factor(level),\n    data = long_TLC, corr = corCompSymm(form = ~factor(level) | id), weights = varIdent(form = ~1 |\n        factor(level)), method = \"REML\")\n\nWe can compare these models using anova.\n\n# compare three models together\nanova(mod_1_unstruc, mod_1_exch_const, mod_1_exch_heter)\n\n                 Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nmod_1_unstruc        1 18 2452.076 2523.559 -1208.038                        \nmod_1_exch_const     2 10 2480.621 2520.334 -1230.311 1 vs 2 44.54508  &lt;.0001\nmod_1_exch_heter     3 13 2459.960 2511.587 -1216.980 2 vs 3 26.66058  &lt;.0001\n\n\n\n# or compare two models at a time\nanova(mod_1_unstruc, mod_1_exch_const)\n\n                 Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nmod_1_unstruc        1 18 2452.076 2523.559 -1208.038                        \nmod_1_exch_const     2 10 2480.621 2520.334 -1230.311 1 vs 2 44.54508  &lt;.0001\n\nanova(mod_1_exch_const, mod_1_exch_heter)\n\n                 Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nmod_1_exch_const     1 10 2480.621 2520.334 -1230.311                        \nmod_1_exch_heter     2 13 2459.960 2511.587 -1216.980 1 vs 2 26.66058  &lt;.0001\n\n\nFor model selection, we want to compare AIC and BIC. The model with the unstructured covariance (e.g., mod_1_unstruc) has the lowest AIC. The model with the exchangeable (heterogeneous variances) (e.g., mod_1_exch_heter) has the lowest BIC. These results suggest that the exchangeable (heterogeneous variances) fits the data best since it is more parsimonious and has low information. Based on the likelihood ratio test, the mod_1_exch_heter model is a significantly better fit than the other two models."
  },
  {
    "objectID": "Longi_GEE.html#more-marginal-models",
    "href": "Longi_GEE.html#more-marginal-models",
    "title": "2  Marginal Model (GEE)",
    "section": "2.6 More Marginal Models",
    "text": "2.6 More Marginal Models\nModel 1: time is categorical, main effects, interaction terms\nModel 1: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T_1}T_1 + \\beta_{T_4}T_4 + \\beta_{T_6}T_6 + \\beta_{trt:T_1}trt*T_1+ \\beta_{trt:T_4}trt*T_4 + \\beta_{trt:T_6}trt*T_6\\)\nThis model includes time as a categorical covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\nmodel_1 &lt;- geeglm(measurements ~ group + as.factor(time) + as.factor(time) * group,\n    id = id, data = long_TLC, family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n# Print summary\nsummary(model_1)\n\n\nCall:\ngeeglm(formula = measurements ~ group + as.factor(time) + as.factor(time) * \n    group, family = gaussian(link = \"identity\"), data = long_TLC, \n    id = id, corstr = \"unstructured\")\n\n Coefficients:\n                                Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)                       26.272   0.703 1395.12  &lt; 2e-16 ***\ngroupTreatment                     0.268   0.994    0.07   0.7875    \nas.factor(time)1                  -1.612   0.433   13.86   0.0002 ***\nas.factor(time)4                  -2.202   0.439   25.20  5.2e-07 ***\nas.factor(time)6                  -2.626   0.528   24.75  6.5e-07 ***\ngroupTreatment:as.factor(time)1  -11.406   1.109  105.84  &lt; 2e-16 ***\ngroupTreatment:as.factor(time)4   -8.824   1.141   59.82  1.0e-14 ***\ngroupTreatment:as.factor(time)6   -3.152   1.244    6.42   0.0113 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)       43    6.58\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.435  0.0762\nalpha.1:3    0.449  0.0848\nalpha.1:4    0.506  0.0577\nalpha.2:3    0.809  0.1123\nalpha.2:4    0.676  0.1036\nalpha.3:4    0.698  0.1371\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 2: time is continuous, main effects\nModel 2: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T\\)\nThis model includes time as a continuous covariate and doesn’t specify any interaction between treatment and control groups.\n\nmodel_2 &lt;- geeglm(measurements ~ group + time, id = id, data = long_TLC, family = gaussian(link = \"identity\"),\n    corstr = \"unstructured\")\n\n# Print summary\nsummary(model_2)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time, family = gaussian(link = \"identity\"), \n    data = long_TLC, id = id, corstr = \"unstructured\")\n\n Coefficients:\n               Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)     25.5006  0.7040 1312.05  &lt; 2e-16 ***\ngroupTreatment  -5.3442  1.0307   26.89  2.2e-07 ***\ntime            -0.1510  0.0913    2.74    0.098 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)       56    7.57\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2  -0.0399  0.1068\nalpha.1:3   0.1088  0.1099\nalpha.1:4   0.4679  0.0820\nalpha.2:3   0.8603  0.0929\nalpha.2:4   0.4375  0.1145\nalpha.3:4   0.4881  0.1208\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 3: time is continuous, main effects, interaction term\nModel 3: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T + \\beta_{trt:T}trt*T\\)\nThis model includes time as a continuous covariate and also includes an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\n# Define Model 3 and label it as: model_3\nmodel_3 &lt;- geeglm(measurements ~ group + time + time * group, id = id, data = long_TLC,\n    family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n# Print summary\nsummary(model_3)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time + time * group, \n    family = gaussian(link = \"identity\"), data = long_TLC, id = id, \n    corstr = \"unstructured\")\n\n Coefficients:\n                    Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)           25.589   0.707 1309.53  &lt; 2e-16 ***\ngroupTreatment        -5.694   1.054   29.19  6.5e-08 ***\ntime                  -0.265   0.102    6.74   0.0094 ** \ngroupTreatment:time    0.600   0.203    8.76   0.0031 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)     58.6    7.61\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2 -0.06469  0.1038\nalpha.1:3  0.00237  0.1233\nalpha.1:4  0.30449  0.1035\nalpha.2:3  0.92472  0.0824\nalpha.2:4  0.56396  0.1051\nalpha.3:4  0.56953  0.1160\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 4: time is continuous, time^2, main effects\nModel 4: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T + \\beta_{T^2}T^2\\)\nThis model treats time as a continuous covariate and also introduces a quadratic term. As a general note when adding quadratic, or higher power terms, into your regression you can either create a new covariate in your dataframe and put that into your formula, or you can take the existing one and specify the term as “I(x^2)”.\n\n# Define Model 4 and label it as: model_4\nmodel_4 &lt;- geeglm(measurements ~ group + time + I(time^2), id = id, data = long_TLC,\n    family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n\n# Print summary\nsummary(model_4)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time + I(time^2), family = gaussian(link = \"identity\"), \n    data = long_TLC, id = id, corstr = \"unstructured\")\n\n Coefficients:\n               Estimate Std.err   Wald Pr(&gt;|W|)    \n(Intercept)     26.1837  0.7144 1343.5  &lt; 2e-16 ***\ngroupTreatment  -5.1837  1.0267   25.5  4.4e-07 ***\ntime            -2.0829  0.4685   19.8  8.7e-06 ***\nI(time^2)        0.3299  0.0809   16.6  4.5e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)     52.3    6.93\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.055  0.1133\nalpha.1:3    0.241  0.1109\nalpha.1:4    0.435  0.0903\nalpha.2:3    0.801  0.1005\nalpha.2:4    0.531  0.1120\nalpha.3:4    0.548  0.1177\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nModel 5: time is continuous, time^2, main effects, interaction\nModel 5: \\(E(y_{ij} \\mid X_{ij}) = \\beta_0 + \\beta_{trt}trt + \\beta_{T}T + \\beta_{T^2}T^2 + \\beta_{trt:T}trt*T+\\beta_{trt:T^2}trt*T^2\\)\nThis model includes time as a continuous covariate and also includes a quadratic term to capture any possible non-linearity in time and an interaction term to account and adjust for any possible discrepancies between the treatment and control.\n\n# Define Model 5 and label it as: model_5\n\nmodel_5 &lt;- geeglm(measurements ~ group + time + I(time^2) + group:(time + I(time^2)),\n    id = id, data = long_TLC, family = gaussian(link = \"identity\"), corstr = \"unstructured\")\n# Print summary\nsummary(model_5)\n\n\nCall:\ngeeglm(formula = measurements ~ group + time + I(time^2) + group:(time + \n    I(time^2)), family = gaussian(link = \"identity\"), data = long_TLC, \n    id = id, corstr = \"unstructured\")\n\n Coefficients:\n                         Estimate Std.err    Wald Pr(&gt;|W|)    \n(Intercept)               25.7785  0.6915 1389.59  &lt; 2e-16 ***\ngroupTreatment            -3.4262  1.0497   10.65   0.0011 ** \ntime                      -0.6750  0.2567    6.91   0.0085 ** \nI(time^2)                  0.0619  0.0417    2.20   0.1377    \ngroupTreatment:time       -4.8098  0.8088   35.36  2.7e-09 ***\ngroupTreatment:I(time^2)   0.8814  0.1393   40.00  2.5e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation structure = unstructured \nEstimated Scale Parameters:\n\n            Estimate Std.err\n(Intercept)     48.5     6.6\n  Link = identity \n\nEstimated Correlation Parameters:\n          Estimate Std.err\nalpha.1:2    0.199  0.1099\nalpha.1:3    0.399  0.0988\nalpha.1:4    0.333  0.1149\nalpha.2:3    0.718  0.1067\nalpha.2:4    0.719  0.1011\nalpha.3:4    0.619  0.1175\nNumber of clusters:   100  Maximum cluster size: 4 \n\n\nNow that we have our five models how exactly can we go about choosing which one is the best?\nA common method of model selection is using the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). For reference \\(AIC = 2p - 2log(L)\\) where \\(L\\) is the likelihood and p is the number of covariates (excluding the intercept). Similarly $BIC = plog(n) - 2log(L) $ where n is the sample size of the data. As an aside when we say log() we are strictly talking about the natural logarithm.\nGiven a collection of models \\(\\{ \\mathcal{M}_m \\}^M_{m=1}\\) we would like to know which one to choose. AIC and BIC both reward goodness of fit (as assessed by the likelihood function), but this can lead to problems in overfitting (i.e. using too much information that makes a model too specific). Overfitting could arise because increasing the number of covariates could cause the likelihood \\(\\hat{L}\\) to increase. To counteract this problem both the AIC and BIC introduce a penalty term that is meant to punish models that are built with a high number of predictors (predictors is synonymous with covariates). AIC uses the \\(2p\\) penalty and BIC uses the \\(plog(n)\\) penalty. Unfortunately for us using the AIC and BIC requires for their to be an actual likelihood. GEE’s don’t have likelihood’s attached to them so it would be non-sensical for us to use either AIC or BIC to select a model.\nOne way to work around this issue is through the introduction of the Quasi-likelihood Information Criterion (QIC). Developed by Pan (2001), the QIC is a modification of the AIC for models fitted by GEE. Using the QIC() function from the geepack package we can calculate the QIC’s of each model and see which of the five has the minimum QIC.\n\nQIC_comparisons &lt;- data.frame(`Model Name` = c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\",\n    \"Model 5\"), QIC = c(QIC(model_1)[1], QIC(model_2)[1], QIC(model_3)[1], QIC(model_4)[1],\n    QIC(model_5)[1]))\nQIC_comparisons\n\n  Model.Name   QIC\n1    Model 1 17225\n2    Model 2 22419\n3    Model 3 23441\n4    Model 4 20927\n5    Model 5 19397\n\n\nFrom the above we can see that Model 1 has the smallest QIC out of the five models."
  },
  {
    "objectID": "Longi_mixeffect.html#model-comparison",
    "href": "Longi_mixeffect.html#model-comparison",
    "title": "4  Mixed Effects Model",
    "section": "4.4 Model Comparison",
    "text": "4.4 Model Comparison\nWe are able to compare the models using AIC and BIC. After you write the other models above, run this chunk below.\n\nMixed_Model_comparisons &lt;- data.frame(`Model Name` = c(\"Mixed Model 1\", \"Mixed Model 2\",\n    \"Mixed Model 3\", \"Mixed Model 4\", \"Mixed Model 5\"), AIC = c(AIC(mod_1), AIC(mod_2),\n    AIC(mod_3), AIC(mod_4), AIC(mod_5)), BIC = c(BIC(mod_1), BIC(mod_2), BIC(mod_3),\n    BIC(mod_4), BIC(mod_5)))\nMixed_Model_comparisons\n\n     Model.Name      AIC      BIC\n1 Mixed Model 1 2680.185 2700.143\n2 Mixed Model 2 2678.397 2706.337\n3 Mixed Model 3 2683.108 2707.057\n4 Mixed Model 4 2681.281 2713.213\n5 Mixed Model 5 2573.229 2625.118\n\n\nWhich model would you select?\nAnswer: We would pick Model 5 because it has the lowest AIC and lowest BIC value."
  }
]